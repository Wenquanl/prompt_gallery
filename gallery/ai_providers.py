# gallery/ai_providers.py
import os
import io
import base64
import fal_client
import httpx 
import time
import json
import copy
from openai import OpenAI
from google import genai
from google.genai import types
from PIL import Image

class BaseAIProvider:
    """AI ç”Ÿå›¾æä¾›å•†çš„åŸºç±»ï¼ˆæ¥å£å®šä¹‰ï¼‰"""
    def generate(self, model_config, api_args, base_image_files=None):
        """
        ç»Ÿä¸€æ¥å£
        :param model_config: AI_STUDIO_CONFIG ä¸­çš„æ¨¡å‹é…ç½®å­—å…¸
        :param api_args: ç»„è£…å¥½çš„å‚æ•°å­—å…¸ (åŒ…å« prompt, steps, size ç­‰)
        :param base_image_files: ä¸Šä¼ çš„å‚è€ƒå›¾æ–‡ä»¶å¯¹è±¡åˆ—è¡¨
        :return: ç”Ÿæˆçš„å›¾ç‰‡ URL åˆ—è¡¨ (List[str])
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° generate æ–¹æ³•")


class FalAIProvider(BaseAIProvider):
    """å½“å‰æ­£åœ¨ä½¿ç”¨çš„ Fal.ai æ¥å£é€‚é…å™¨"""
    def generate(self, model_config, api_args, base_image_files=None):
        endpoint = model_config['endpoint']
        category_id = model_config['category']
        os.environ["FAL_KEY"] = os.getenv("FAL_KEY", "")

        # 1. å¤„ç†ä¸Šä¼ å‚è€ƒå›¾
        uploaded_image_urls = []
        if base_image_files:
            for file in base_image_files:
                # æ³¨æ„ï¼šå¦‚æœæœªæ¥å…¶ä»–å¹³å°ä¸éœ€è¦é¢„ä¸Šä¼ å›¾ç‰‡ï¼Œåªéœ€åœ¨å…¶ä»–é€‚é…å™¨é‡Œä¿®æ”¹è¿™éƒ¨åˆ†é€»è¾‘å³å¯
                url = fal_client.upload(file.read(), file.content_type)
                uploaded_image_urls.append(url)
                
            if category_id == 'i2i':
                api_args['image_url'] = uploaded_image_urls[0]
            else:
                api_args['image_urls'] = uploaded_image_urls

        # ==================================
        # ã€æ–°å¢ã€‘ï¼šæ§åˆ¶å°ä¼˜ç¾æ‰“å°
        # ==================================
        print("\n" + "="*60)
        print(f"ğŸš€ [Fal.ai API] æ­£åœ¨è¯·æ±‚æ¨¡å‹: {endpoint}")
        print("ğŸ“¦ æœ€ç»ˆå‘å¾€äº‘ç«¯çš„è¯·æ±‚æŠ¥æ–‡ (Arguments):")
        print(json.dumps(api_args, indent=4, ensure_ascii=False))
        print("="*60 + "\n")

        # 2. è°ƒç”¨ç”Ÿæˆæ¥å£
        result = fal_client.subscribe(endpoint, arguments=api_args)
        
        # 3. ç»Ÿä¸€è¿”å›æ ¼å¼ï¼šæå–å¹¶è¿”å› URL å­—ç¬¦ä¸²åˆ—è¡¨
        gen_images = result.get('images', [])
        return [img.get('url') for img in gen_images if img.get('url')]

class VolcengineProvider(BaseAIProvider):
    def generate(self, model_config, api_args, base_image_files=None):
        client = OpenAI(
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            api_key=os.getenv('ARK_API_KEY')
        )

        model_endpoint = model_config['endpoint']
        prompt = api_args.get('prompt', '')
        size = api_args.get('image_size', '2K')
        max_images = int(api_args.get('max_images', 1))

        # 1. åŸºç¡€ç‰¹æœ‰å‚æ•°ï¼šæ°´å°
        extra_body = {
            "watermark": api_args.get('watermark', False)
        }

        # 2. ç»„å›¾é€»è¾‘ï¼šåªæœ‰æ˜ç¡®è¦æ±‚å¤šå›¾æ—¶ï¼Œæ‰å¼€å¯ sequential_image_generation
        if max_images > 1:
            extra_body["sequential_image_generation"] = "auto"
            extra_body["sequential_image_generation_options"] = {"max_images": max_images}

        # 3. å¤„ç†å‚è€ƒå«å›¾ (Base64)
        encoded_images = []
        if base_image_files:
            for file in base_image_files:
                # è·å–æ–‡ä»¶çš„ MIME ç±»å‹ (ä¾‹å¦‚ 'image/png', 'image/jpeg')
                # Django çš„ UploadedFile å¯¹è±¡å¸¦æœ‰ content_type å±æ€§
                mime_type = getattr(file, 'content_type', 'image/jpeg')
                
                # è¯»å–å¹¶è½¬ä¸º Base64
                file_content = file.read()
                base64_str = base64.b64encode(file_content).decode('utf-8')
                
                # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šæ‹¼æ¥æˆæ ‡å‡†çš„ Data URL æ ¼å¼ï¼Œè¿™è¢«è§†ä¸ºåˆæ³•çš„ URL
                data_url = f"data:{mime_type};base64,{base64_str}"
                encoded_images.append(data_url)
                
            if len(encoded_images) == 1:
                extra_body["image"] = encoded_images[0] # å•å›¾æ¨¡å¼ä¼ å­—ç¬¦ä¸²
            elif len(encoded_images) > 1:
                extra_body["image"] = encoded_images    # å¤šå›¾æ¨¡å¼ä¼ åˆ—è¡¨

        # 4. æé€Ÿæ¨¡å¼æ”¯æŒ (ä»…é™ Seedream 4.0)
        optimize_mode = api_args.get('optimize_prompt_mode')
        if optimize_mode == 'fast':
            extra_body["optimize_prompt_options"] = {"mode": "fast"}

        # 5. æ‹¼è£…æ ¸å¿ƒè¯·æ±‚ä½“
        request_payload = {
            "model": model_endpoint,
            "prompt": prompt,
            "size": size,
            "response_format": "url",
        }

        # 6. è¾“å‡ºæ ¼å¼æ”¯æŒ (ä»…é™ 5.0 lite æ”¯æŒé…ç½®)
        if 'output_format' in api_args:
            request_payload["output_format"] = api_args['output_format']

        # 7. è”ç½‘æœç´¢æ”¯æŒ (ä»…é™ 5.0 lite)
        if api_args.get('enable_web_search'):
            extra_body["tools"] = [{"type": "web_search"}]
        request_payload["extra_body"] = extra_body
        # ==================================
        # ã€æ–°å¢ã€‘ï¼šæ§åˆ¶å°ä¼˜ç¾æ‰“å°å®Œæ•´è¯·æ±‚æŠ¥æ–‡
        # ==================================
        debug_payload = copy.deepcopy(request_payload)
        
        # è¿‡æ»¤æ‰è¶…é•¿çš„ Base64 å›¾ç‰‡å­—ç¬¦ä¸²ï¼Œé˜²æ­¢æŠŠæ§åˆ¶å°åˆ·å±å¡æ­»
        if "extra_body" in debug_payload and "image" in debug_payload["extra_body"]:
            img_data = debug_payload["extra_body"]["image"]
            if isinstance(img_data, list):
                debug_payload["extra_body"]["image"] = [f"<å›¾ç‰‡ Base64 æ•°æ®, é•¿åº¦: {len(i)}>" for i in img_data]
            else:
                debug_payload["extra_body"]["image"] = f"<å•å¼ å›¾ç‰‡ Base64 æ•°æ®, é•¿åº¦: {len(img_data)}>"

        print("\n" + "="*60)
        print(f"ğŸš€ [Volcengine API] æ­£åœ¨è¯·æ±‚ç«å±±å¼•æ“èŠ‚ç‚¹...")
        print("ğŸ“¦ æœ€ç»ˆå‘å¾€äº‘ç«¯çš„è¯·æ±‚æŠ¥æ–‡ (Payload):")
        print(json.dumps(debug_payload, indent=4, ensure_ascii=False))
        print("="*60 + "\n")
        # ==================================
        # è°ƒç”¨å®˜æ–¹æ¥å£
        # ==================================
        response = client.images.generate(**request_payload)

        # è§£æè¿”å›çš„ URL
        urls = []
        if response.data:
            for img_obj in response.data:
                # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šåªæœ‰å½“ url å­˜åœ¨ä¸”ä¸ä¸ºç©ºæ—¶ï¼Œæ‰åŠ å…¥åˆ—è¡¨
                if getattr(img_obj, 'url', None):
                    urls.append(img_obj.url)
                
        return urls

class GoogleAIProvider(BaseAIProvider):
    def generate(self, model_config, api_args, base_image_files=None):
        # 1. è·å–åä»£åœ°å€
        base_url = os.getenv("GOOGLE_API_BASE_URL", "https://generativelanguage.googleapis.com")
        proxy_token = os.getenv("GOOGLE_PROXY_TOKEN", "")
        # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šæ‰‹åŠ¨æ„é€  Headerï¼Œå¼ºåˆ¶è¦†ç›– SDK è‡ªåŠ¨ç”Ÿæˆçš„ 1s
        # 1. è¿™é‡Œæ˜¯ä¼ ç»™åº•å±‚ httpx çš„ï¼Œå•ä½å¿…é¡»æ˜¯ã€ç§’ã€‘(æµ®ç‚¹æ•°)
        client_args = {
            "http2": False,
            "headers": {
                "X-Proxy-Token": proxy_token
            },
            "timeout": 600.0  # 600æ¯«ç§’
        }

        # 2. åˆå§‹åŒ– Client
        client = genai.Client(
            api_key=os.getenv("GEMINI_API_KEY"),
            http_options=types.HttpOptions(
                api_version="v1beta",
                base_url=base_url,
                # ã€æ ¸å¿ƒä¿®å¤ï¼ï¼ï¼ã€‘ï¼šè¿™é‡Œä¼ ç»™ Google SDKï¼Œå•ä½å¿…é¡»æ˜¯ã€æ¯«ç§’ã€‘(æ•´æ•°)
                # 600 ç§’ * 1000 = 600,000 æ¯«ç§’
                timeout=600000, 
                client_args=client_args,
                async_client_args=client_args
            )
        )
        model_endpoint = model_config['endpoint']

        # ==========================================
        # 3. æ„å»ºå¤šæ¨¡æ€è¾“å…¥ (Contents Array)
        # Nano Banana å…è®¸åŒæ—¶ä¼ å…¥æ–‡æœ¬å’Œå¤šè¾¾ 14 å¼ å‚è€ƒå›¾ç‰‡
        # ==========================================
        contents = []
        if api_args.get('prompt'):
            contents.append(api_args['prompt'])

        if base_image_files:
            for f in base_image_files:
                # ã€æ–°å¢ï¼šå®‰å…¨æ€§é«˜çš„å‹ç¼©é€»è¾‘ã€‘
                img = Image.open(f)
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                max_size = 1024
                if img.width > max_size or img.height > max_size:
                    # ä½¿ç”¨ LANCZOS ç®—æ³•ä¿æŒç¼©æ”¾åçš„æ¸…æ™°åº¦
                    img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                
                output = io.BytesIO()
                # å¼ºè¡Œå‹ç¼©åˆ° 80% è´¨é‡ï¼Œå‡å° MTU å‹åŠ›
                img.save(output, format='JPEG', quality=80, optimize=True)
                img_bytes = output.getvalue()
                
                contents.append(
                    types.Part.from_bytes(data=img_bytes, mime_type='image/jpeg')
                )

        # ==========================================
        # 4. æ„å»ºç”Ÿå›¾å‚æ•°ä¸æ ¸å¿ƒé…ç½® (Config)
        # ==========================================
        image_config_kwargs = {
            "aspect_ratio": api_args.get('aspect_ratio', '1:1'),
        }
        # å¦‚æœå‰ç«¯ä¼ äº†åˆ†è¾¨ç‡å‚æ•°ï¼Œåˆ™åŠ ä¸Š (å¦‚ "2K", "4K")
        if 'resolution' in api_args:
            image_config_kwargs["image_size"] = api_args['resolution']
            
        config_kwargs = {
            # å¼ºåˆ¶åªè¿”å›å›¾åƒï¼Œé¿å…æ¨¡å‹å•°å—¦è¿”å›æ–‡æœ¬å¯¼è‡´è§£æå¤æ‚
            "response_modalities": ["IMAGE"], 
            "image_config": types.ImageConfig(**image_config_kwargs)
        }

        # ğŸ’¡ ç‰¹æ€§ Aï¼šå¯ç”¨ Google è”ç½‘æœç´¢
        if api_args.get('enable_web_search'):
            # å¼€å¯ç½‘é¡µæœç´¢å’Œå›¾ç‰‡æœç´¢åŒé‡ Grounding
            config_kwargs["tools"] = [
                types.Tool(google_search=types.GoogleSearch(
                    search_types=types.SearchTypes(
                        web_search=types.WebSearch(),
                        image_search=types.ImageSearch()
                    )
                ))
            ]

        # ğŸ’¡ ç‰¹æ€§ Bï¼šæ§åˆ¶æ€è€ƒæ·±åº¦ (ç›®å‰ä»…é™ Gemini 3.1 Flash æ”¯æŒ)
        if api_args.get('thinking_level'):
            config_kwargs["thinking_config"] = types.ThinkingConfig(
                thinking_level=api_args['thinking_level'],
                include_thoughts=False # è®¾ä¸º Falseï¼Œé¿å…è¿”å›è¿‡ç¨‹ä¸­çš„è‰å›¾å¹²æ‰°æœ€ç»ˆç»“æœ
            )

        config = types.GenerateContentConfig(**config_kwargs)

        # ==================================
        # ã€æ–°å¢ã€‘ï¼šæ§åˆ¶å°ä¼˜ç¾æ‰“å°å®Œæ•´è¯·æ±‚æŠ¥æ–‡ (Google SDK ç‰ˆ)
        # ==================================
        # å› ä¸º Google SDK ä¼ çš„æ˜¯å¯¹è±¡ï¼Œæˆ‘ä»¬æ‰‹åŠ¨æå–å¹¶æ‹¼è£…æˆç›´è§‚çš„å­—å…¸ç”¨äºæ‰“å°
        debug_contents = []
        for item in contents:
            if isinstance(item, str):
                debug_contents.append(item) # æ–‡æœ¬æç¤ºè¯ç›´æ¥æ‰“å°
            elif hasattr(item, 'inline_data') and item.inline_data:
                debug_contents.append(f"<å‚è€ƒå›¾äºŒè¿›åˆ¶æµ, é•¿åº¦: {len(item.inline_data.data)} bytes, æ ¼å¼: {item.inline_data.mime_type}>")
            else:
                debug_contents.append("<æœªçŸ¥å¤šæ¨¡æ€æ•°æ®å—>")

        # è¿˜åŸ Config å‚æ•°ç”¨äºå±•ç¤º
        debug_config = {
            "response_modalities": ["IMAGE"],
            "image_config": image_config_kwargs,
        }
        if api_args.get('enable_web_search'):
            debug_config["tools"] = [{"google_search": "enabled"}]
        if api_args.get('thinking_level'):
            debug_config["thinking_config"] = {
                "thinking_level": api_args['thinking_level'],
                "include_thoughts": False
            }

        debug_payload = {
            "model": model_endpoint,
            "contents": debug_contents,
            "config": debug_config
        }

        print("\n" + "="*60)
        print(f"ğŸš€ [Google AI API] æ­£åœ¨è¯·æ±‚ Google Gemini èŠ‚ç‚¹...")
        print("ğŸ“¦ æœ€ç»ˆå‘å¾€äº‘ç«¯çš„è¯·æ±‚ç»“æ„ (Parsed Payload):")
        print(json.dumps(debug_payload, indent=4, ensure_ascii=False))
        print("="*60 + "\n")
        start_time = time.time()
        try:
            response = client.models.generate_content(
                model=model_endpoint,
                contents=contents,
                config=config
            )
        except Exception as e:
            # è¯·æ±‚å¤±è´¥æ—¶ä¹Ÿè®¡ç®—ä¸€ä¸‹èŠ±äº†å¤šä¹…æ‰æŠ¥é”™ï¼ˆæ¯”å¦‚æ’æŸ¥æ˜¯å¦æ˜¯è¶…æ—¶æ–­å¼€ï¼‰
            elapsed_time = time.time() - start_time
            raise Exception(f"é€šä¿¡å¤±è´¥ (è€—æ—¶ {elapsed_time:.2f} ç§’): {str(e)}")
        
        # è®°å½•è¯·æ±‚ç»“æŸæ—¶é—´ï¼Œå¹¶è®¡ç®—è€—æ—¶
        elapsed_time = time.time() - start_time
        
        # ==================================
        # æ§åˆ¶å°ä¼˜ç¾æ‰“å°å®Œæ•´å“åº”æŠ¥æ–‡ (Google SDK ç‰ˆ)
        # ==================================
        print("\n" + "="*60)
        print(f"âœ… [Google AI API] æˆåŠŸæ¥æ”¶åˆ° Google Gemini èŠ‚ç‚¹çš„å“åº”ï¼(æ€»è€—æ—¶: â±ï¸ {elapsed_time:.2f} ç§’)")
        print("ğŸ“¥ å“åº”è¯¦æƒ…å‰–æ (å·²è‡ªåŠ¨è¿‡æ»¤è¶…é•¿å›¾ç‰‡æµï¼Œé˜²æ­¢åˆ·å±)ï¼š")
        # å®‰å…¨åœ°æå–å“åº”ä½“ä¸­çš„å…³é”®ä¿¡æ¯è¿›è¡Œç»„è£…
        debug_response = {
            "prompt_feedback": str(getattr(response, 'prompt_feedback', 'æ— æ‹¦æˆªåé¦ˆ')),
            "candidates_count": len(response.candidates) if getattr(response, 'candidates', None) else 0,
            "candidates": []
        }
        if getattr(response, 'candidates', None):
            for i, cand in enumerate(response.candidates):
                # è§£æåœæ­¢åŸå› 
                finish_reason_str = cand.finish_reason.name if hasattr(cand.finish_reason, 'name') else str(getattr(cand, 'finish_reason', 'æœªçŸ¥'))
                
                cand_info = {
                    "index": i,
                    "finish_reason": finish_reason_str,
                    "safety_ratings": [],
                    "parts": []
                }
                
                # æå–å®‰å…¨å®¡æŸ¥è¯„åˆ† (éå¸¸æœ‰åŠ©äºæ’æŸ¥ä¸ºä»€ä¹ˆå›¾å‡ºä¸æ¥)
                if getattr(cand, 'safety_ratings', None):
                    for sr in cand.safety_ratings:
                        category = sr.category.name if hasattr(sr.category, 'name') else str(sr.category)
                        probability = sr.probability.name if hasattr(sr.probability, 'name') else str(sr.probability)
                        cand_info["safety_ratings"].append(f"{category}: {probability}")

                # æå–è¿”å›çš„å†…å®¹å—
                if getattr(cand, 'content', None) and getattr(cand.content, 'parts', None):
                    for part in cand.content.parts:
                        if getattr(part, 'text', None):
                            # å¦‚æœæ¨¡å‹é™„å¸¦è¿”å›äº†æ–‡æœ¬ï¼ˆä¾‹å¦‚æ€è€ƒè¿‡ç¨‹æˆ–è­¦å‘Šï¼‰
                            cand_info["parts"].append({"text": part.text})
                        elif getattr(part, 'inline_data', None):
                            # ã€æ ¸å¿ƒã€‘ï¼šä¸è¦ç›´æ¥æ‰“å°äºŒè¿›åˆ¶æ•°æ®ï¼Œç”¨æç¤ºè¯­æ›¿ä»£
                            mime = part.inline_data.mime_type or 'æœªçŸ¥ç±»å‹'
                            size = len(part.inline_data.data) if part.inline_data.data else 0
                            cand_info["parts"].append(f"<ğŸ–¼ï¸ æˆåŠŸæ¥æ”¶å›¾ç‰‡äºŒè¿›åˆ¶æµ, MIME: {mime}, å¤§å°: {size} bytes>")
                        else:
                            cand_info["parts"].append("<æœªçŸ¥æ•°æ®å—>")
                
                debug_response["candidates"].append(cand_info)

        # æå– Token æ¶ˆè€—ç­‰å…ƒæ•°æ® (å¦‚æœ SDK æœ‰è¿”å›)
        if getattr(response, 'usage_metadata', None):
            debug_response["usage_metadata"] = {
                "prompt_token_count": getattr(response.usage_metadata, 'prompt_token_count', 0),
                "candidates_token_count": getattr(response.usage_metadata, 'candidates_token_count', 0),
                "total_token_count": getattr(response.usage_metadata, 'total_token_count', 0),
            }

        print(json.dumps(debug_response, indent=4, ensure_ascii=False))
        print("="*60 + "\n")

        # 2. æ£€æŸ¥æç¤ºè¯æ˜¯å¦åœ¨è¿›æ¨¡å‹å‰å°±è¢«ç›´æ¥æ‹‰é»‘ (Prompt Feedback)
        if getattr(response, 'prompt_feedback', None):
            feedback = response.prompt_feedback
            if getattr(feedback, 'block_reason', None):
                raise Exception(f"ğŸš« è¯·æ±‚è¢«æ‹’ç»ï¼šæç¤ºè¯è§¦å‘äº†ä¸¥é‡è¿è§„æ‹¦æˆªï¼ŒåŸå› ä»£ç  [{feedback.block_reason}]ã€‚")

        # 3. æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰ç»“æœ
        if not response.candidates:
            # å¦‚æœä»€ä¹ˆéƒ½æ²¡è¿”å›ï¼ŒæŠŠåŸå§‹å“åº”æŠ›å‡ºï¼Œæ–¹ä¾¿åœ¨å‰ç«¯/æ—¥å¿—é‡ŒæŸ¥é”™
            raise Exception(f"â“ äº‘ç«¯æœªè¿”å›ä»»ä½•å†…å®¹ã€‚åŸå§‹å“åº”æ•°æ®: {response}")

        candidate = response.candidates[0]
        
        # 4. æ ¸å¿ƒï¼šè§£ææ¨¡å‹åœæ­¢ç”Ÿæˆçš„åŸå›  (Finish Reason)
        finish_reason = getattr(candidate, 'finish_reason', None)
        
        if finish_reason:
            # å°† Enum ç±»å‹å®‰å…¨åœ°è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¦‚ 'IMAGE_SAFETY'
            reason_str = finish_reason.name if hasattr(finish_reason, 'name') else str(finish_reason)
            
            # å¯¹ç…§ Google å®˜æ–¹æ–‡æ¡£çš„æ‹¦æˆªä»£ç è¿›è¡Œâ€œäººè¯â€ç¿»è¯‘
            if reason_str in ['IMAGE_SAFETY', 'SAFETY']:
                raise Exception("ğŸ›¡ï¸ è§¦å‘äº†å®‰å…¨å®¡æŸ¥ (SAFETY)ï¼šæç¤ºè¯æˆ–å‚è€ƒå›¾å¯èƒ½åŒ…å«æš´éœ²ã€æš´åŠ›æˆ–å—ç‰ˆæƒä¿æŠ¤çš„å†…å®¹ã€‚è¯·è„±æ•åé‡è¯•ï¼")
            elif reason_str == 'PROHIBITED_CONTENT':
                raise Exception("ğŸš« è§¦å‘è¿ç¦å†…å®¹æ‹¦æˆªï¼šæ‚¨çš„è¯·æ±‚åŒ…å«äº†æ¨¡å‹ä¸¥æ ¼ç¦æ­¢çš„è¯æ±‡æˆ–æŒ‡ä»¤ã€‚")
            elif reason_str == 'RECITATION':
                raise Exception("Â©ï¸ è§¦å‘ç‰ˆæƒæ‹¦æˆª (RECITATION)ï¼šç”Ÿæˆå†…å®¹ç–‘ä¼¼æŠ„è¢­å—ä¿æŠ¤çš„æºæ•°æ®ï¼Œè¯·ä¿®æ”¹æè¿°ã€‚")
            elif reason_str == 'MAX_TOKENS':
                raise Exception("â³ ç”Ÿæˆä¸­æ–­ï¼šè¾¾åˆ°äº†æœ€å¤§çš„ Token è®¡ç®—é™åˆ¶ã€‚")
            elif reason_str == 'OTHER':
                raise Exception("ğŸ›‘ ç”Ÿæˆè¢«æ‹¦æˆª (OTHER)ï¼šè§¦å‘äº†æœªå…¬å¼€çš„ç³»ç»Ÿå®‰å…¨ç­–ç•¥ã€‚")
            elif reason_str != 'STOP': 
                # STOP æ˜¯æ­£å¸¸å‡ºå›¾çš„æ ‡å¿—ã€‚å¦‚æœä¸æ˜¯ STOP ä¹Ÿä¸æ˜¯ä¸Šé¢çš„å·²çŸ¥é”™è¯¯ï¼Œå°±æŠ›å‡ºåŸå§‹å†…å®¹
                raise Exception(f"âš ï¸ ç”Ÿæˆæœªæ­£å¸¸å®Œæˆï¼Œä¸­æ–­åŸå› : {reason_str}")
            elif reason_str in ['OTHER', 'IMAGE_OTHER']: # <--- ã€åœ¨è¿™é‡ŒåŠ ä¸Š IMAGE_OTHERã€‘
                raise Exception("ğŸ›‘ ç”Ÿæˆå¤±è´¥ï¼šå¼•æ“å†…éƒ¨æ¸²æŸ“é”™è¯¯æˆ–è§¦å‘äº†éšè—çš„é£æ§ç­–ç•¥ï¼Œè¯·å°è¯•ç¨å¾®ä¿®æ”¹æç¤ºè¯åé‡è¯•ã€‚")
        
        # ==========================================
        # æå–å›¾ç‰‡æ•°æ®
        # ==========================================
        urls = []
        if getattr(response, 'parts', None):
            for part in response.parts:
                if getattr(part, 'inline_data', None):
                    img_bytes = part.inline_data.data
                    mime = part.inline_data.mime_type or 'image/jpeg'
                    b64_str = base64.b64encode(img_bytes).decode('utf-8')
                    urls.append(f"data:{mime};base64,{b64_str}")
        
        # 5. ç»ˆæå…œåº•ï¼šå¦‚æœçŠ¶æ€æ­£å¸¸ï¼Œä½†å°±æ˜¯æ²¡æœ‰å›¾ç‰‡æ•°æ®
        if not urls:
            raise Exception(f"ğŸ“¦ äº‘ç«¯è¿”å›äº†æˆåŠŸçŠ¶æ€ï¼Œä½†åŒ…è£¹é‡Œæ²¡æœ‰å›¾ç‰‡æ•°æ®ã€‚åŸå§‹å“åº”: {response}")

        return urls
# ==========================================
# å·¥å‚æ¨¡å¼ï¼šæ ¹æ®åç§°è¿”å›å¯¹åº”çš„å¤„ç†ç±»
# ==========================================
def get_ai_provider(provider_name="fal_ai"):
    providers = {
        'fal_ai': FalAIProvider(),
        'volcengine': VolcengineProvider(),
        'google_ai': GoogleAIProvider(), 
    }
    return providers.get(provider_name, FalAIProvider())