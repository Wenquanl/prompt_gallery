import os
import time
import difflib
import uuid
import json
import re
import shutil
import fal_client
import requests
import base64
import warnings # æ–°å¢å¼•å…¥ warnings æ¨¡å—
from urllib3.exceptions import InsecureRequestWarning # å¼•å…¥å…·ä½“çš„è­¦å‘Šç±»å‹
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib import messages
from django.conf import settings
from django.http import JsonResponse
from django.db.models import Q, Count, Case, When, IntegerField, Max, Prefetch
from django.db import transaction
from django.core.files.base import ContentFile
from django.core.paginator import Paginator
from django.views.decorators.http import require_GET, require_POST
from django.core.cache import cache
from django.template.loader import render_to_string
from django.views.decorators.csrf import csrf_exempt
from .models import ImageItem, PromptGroup, Tag, AIModel, ReferenceItem, Character
from .forms import PromptGroupForm
from .ai_utils import search_similar_images, generate_title_with_local_llm
from .ai_providers import get_ai_provider

# === å¼•å…¥ Service å±‚ ===
from .services import (
    get_temp_dir, 
    calculate_file_hash, 
    trigger_background_processing,
    confirm_upload_images
)

# ==========================================
# ç»ˆæé…ç½®ä¸­å¿ƒ (Single Source of Truth)
# ==========================================
warnings.filterwarnings("ignore", category=InsecureRequestWarning)
AI_STUDIO_CONFIG = {
    # 1. å¤§ç±»å®šä¹‰
    'categories': [
        {'id': 'multi', 'title': 'ğŸŸ¢ å¤šå›¾èåˆ', 'img_max': 10, 'img_help': 'å½“å‰ä¸ºå¤šå›¾æ¨¡å¼ï¼šæŒ‰ä½ Ctrl é”®å¯å¤šé€‰ (æœ€å¤š10å¼ )'},
        {'id': 'i2i', 'title': 'ğŸ”µ å›¾ç”Ÿå›¾', 'img_max': 1, 'img_help': 'å½“å‰ä¸ºå•å›¾æ¨¡å¼ï¼šè¯·ä¸Šä¼  1 å¼ å‚è€ƒå›¾ç‰‡'},
        {'id': 't2i', 'title': 'ğŸŸ  æ–‡ç”Ÿå›¾', 'img_max': 0, 'img_help': 'çº¯æ–‡æœ¬æ¨¡å¼ï¼Œæ— éœ€ä¼ å›¾'},
    ],
    # 2. å…·ä½“æ¨¡å‹å®šä¹‰
    'models': {
        'flux-dev': {
            'provider': 'fal_ai',
            'category': 't2i',
            'endpoint': 'fal-ai/flux/dev',
            'title': 'Flux Dev',
            'desc': 'æ¨èï¼Œç”Ÿæˆè´¨é‡æé«˜ï¼Œè¯­ä¹‰ç†è§£ç²¾å‡†',
            'params': [
                {'id': 'image_size', 'label': 'å›¾ç‰‡ç”»å¹… (Size)', 'type': 'select', 'options': [
                    {'value': 'landscape_4_3', 'text': 'æ¨ªç‰ˆ 4:3 (é»˜è®¤)'},
                    {'value': 'portrait_4_3', 'text': 'ç«–ç‰ˆ 3:4'},
                    {'value': 'square_hd', 'text': 'æ­£æ–¹å½¢ HD'}
                ], 'default': 'landscape_4_3'},
                {'id': 'num_inference_steps', 'label': 'ç”Ÿæˆæ­¥æ•° (Steps)', 'type': 'range', 'min': 20, 'max': 50, 'step': 1, 'default': 28}
            ]
        },
        'flux-dev-i2i': {
            'provider': 'fal_ai',
            'category': 'i2i',
            'endpoint': 'fal-ai/flux/dev/image-to-image',
            'title': 'Flux i2i',
            'desc': 'Flux Dev çš„å›¾ç”Ÿå›¾å¼ºåŒ–å˜ä½“',
            'params': [
                {'id': 'strength', 'label': 'é‡ç»˜å¹…åº¦ (Strength)', 'type': 'range', 'min': 0.1, 'max': 1.0, 'step': 0.05, 'default': 0.75},
                {'id': 'num_inference_steps', 'label': 'ç”Ÿæˆæ­¥æ•° (Steps)', 'type': 'range', 'min': 20, 'max': 50, 'step': 1, 'default': 28}
            ]
        },
        'seedream-5.0-lite-official': {
            'provider': 'volcengine',
            'category': 'multi',
            'endpoint': 'doubao-seedream-5-0-260128', 
            'title': 'Seedream 5.0 Lite (å®˜æ–¹)',
            'desc': 'å­—èŠ‚å®˜æ–¹æœ€æ–° APIï¼Œæ”¯æŒå¤šå›¾èåˆã€ç»„å›¾ç”Ÿæˆä¸è”ç½‘æœç´¢',
            'params': [
                {'id': 'max_images', 'label': 'ç”Ÿæˆç»„å›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'image_size', 'label': 'ç”Ÿæˆå°ºå¯¸ (Size)', 'type': 'select', 'options': [
                    {'value': '2K', 'text': '2K (é»˜è®¤)'},
                    {'value': '3K', 'text': '3K (è¶…æ¸…)'},
                ], 'default': '2K'},
                {'id': 'prompt_aspect_ratio', 'label': 'ç”»é¢æ¯”ä¾‹ (ä»…è¿½åŠ åˆ°æç¤ºè¯)', 'type': 'select', 'options': [
                    {'value': 'none', 'text': 'ä¸æŒ‡å®š'},
                    {'value': '1:1', 'text': '1:1 (æ­£æ–¹å½¢)'},
                    {'value': '3:4', 'text': '3:4 (ç«–ç‰ˆ)'},
                    {'value': '4:3', 'text': '4:3 (æ¨ªç‰ˆ)'},
                    {'value': '16:9', 'text': '16:9 (æ¨ªç‰ˆ)'},
                    {'value': '9:16', 'text': '9:16 (ç«–ç‰ˆ)'},
                    {'value': '3:2', 'text': '3:2 (æ¨ªç‰ˆ)'},
                    {'value': '2:3', 'text': '2:3 (ç«–ç‰ˆ)'},
                    {'value': '21:9', 'text': '21:9 (å®½å±)'}
                ], 'default': '9:16'},
                {'id': 'output_format', 'label': 'è¾“å‡ºæ ¼å¼', 'type': 'select', 'options': [
                    {'value': 'png', 'text': 'PNG'},
                    {'value': 'jpeg', 'text': 'JPEG'}
                ], 'default': 'png'},
                {'id': 'watermark', 'label': 'æ·»åŠ å®˜æ–¹æ°´å°', 'type': 'checkbox', 'default': False},
                {'id': 'enable_web_search', 'label': 'å¼€å¯è”ç½‘æœç´¢', 'type': 'checkbox', 'default': False, 'help_text': 'å¼€å¯åæ¨¡å‹ä¼šæ ¹æ®æç¤ºè¯è‡ªä¸»æœç´¢äº’è”ç½‘å†…å®¹ï¼ˆå¦‚è¿‘æœŸå¤©æ°”ã€æ–°é—»ç­‰ï¼‰'}
            ]
        },
        'seedream-4.5-official': {
            'provider': 'volcengine',
            'category': 'multi',
            'endpoint': 'doubao-seedream-4-5-251128',
            'title': 'Seedream 4.5 (å®˜æ–¹)',
            'desc': 'å­—èŠ‚å®˜æ–¹ APIï¼Œä¸“æ³¨é«˜è´¨é‡å›¾åƒè¾“å‡º',
            'params': [
                {'id': 'max_images', 'label': 'ç”Ÿæˆç»„å›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'image_size', 'label': 'ç”Ÿæˆå°ºå¯¸ (Size)', 'type': 'select', 'options': [
                    {'value': '2K', 'text': '2K (é»˜è®¤)'},
                    {'value': '4K', 'text': '4K (è¶…æ¸…)'},
                ], 'default': '2K'},
                {'id': 'prompt_aspect_ratio', 'label': 'ç”»é¢æ¯”ä¾‹ (ä»…è¿½åŠ åˆ°æç¤ºè¯)', 'type': 'select', 'options': [
                    {'value': 'none', 'text': 'ä¸æŒ‡å®š'},
                    {'value': '1:1', 'text': '1:1 (æ­£æ–¹å½¢)'},
                    {'value': '3:4', 'text': '3:4 (ç«–ç‰ˆ)'},
                    {'value': '4:3', 'text': '4:3 (æ¨ªç‰ˆ)'},
                    {'value': '16:9', 'text': '16:9 (æ¨ªç‰ˆ)'},
                    {'value': '9:16', 'text': '9:16 (ç«–ç‰ˆ)'},
                    {'value': '3:2', 'text': '3:2 (æ¨ªç‰ˆ)'},
                    {'value': '2:3', 'text': '2:3 (ç«–ç‰ˆ)'},
                    {'value': '21:9', 'text': '21:9 (å®½å±)'}
                ], 'default': '9:16'},
                {'id': 'watermark', 'label': 'æ·»åŠ å®˜æ–¹æ°´å°', 'type': 'checkbox', 'default': False}
                # æ–‡æ¡£æŒ‡å‡º 4.5 é»˜è®¤ jpeg ä¸æ”¯æŒè‡ªå®šä¹‰æ ¼å¼ï¼Œä¸”ä¸æ”¯æŒè”ç½‘æœç´¢ï¼Œæ•…åœ¨æ­¤çœç•¥
            ]
        },
        'seedream-4.0-official': {
            'provider': 'volcengine',
            'category': 'multi',
            'endpoint': 'doubao-seedream-4-0-250828',
            'title': 'Seedream 4.0 (å®˜æ–¹)',
            'desc': 'å­—èŠ‚å®˜æ–¹ APIï¼Œæ”¯æŒç‰ºç‰²éƒ¨åˆ†ç”»è´¨çš„æé€Ÿç”Ÿæˆæ¨¡å¼',
            'params': [
                {'id': 'max_images', 'label': 'ç”Ÿæˆç»„å›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'image_size', 'label': 'ç”Ÿæˆå°ºå¯¸ (Size)', 'type': 'select', 'options': [
                    {'value': '1K', 'text': '1K (è¾ƒå¿«)'},
                    {'value': '2K', 'text': '2K (é»˜è®¤)'},
                    {'value': '4K', 'text': '4K (è¶…æ¸…)'},
                ], 'default': '2K'},
                {'id': 'prompt_aspect_ratio', 'label': 'ç”»é¢æ¯”ä¾‹ (ä»…è¿½åŠ åˆ°æç¤ºè¯)', 'type': 'select', 'options': [
                    {'value': 'none', 'text': 'ä¸æŒ‡å®š'},
                    {'value': '1:1', 'text': '1:1 (æ­£æ–¹å½¢)'},
                    {'value': '3:4', 'text': '3:4 (ç«–ç‰ˆ)'},
                    {'value': '4:3', 'text': '4:3 (æ¨ªç‰ˆ)'},
                    {'value': '16:9', 'text': '16:9 (æ¨ªç‰ˆ)'},
                    {'value': '9:16', 'text': '9:16 (ç«–ç‰ˆ)'},
                    {'value': '3:2', 'text': '3:2 (æ¨ªç‰ˆ)'},
                    {'value': '2:3', 'text': '2:3 (ç«–ç‰ˆ)'},
                    {'value': '21:9', 'text': '21:9 (å®½å±)'}
                ], 'default': '9:16'},
                {'id': 'optimize_prompt_mode', 'label': 'ç”Ÿæˆæ¨¡å¼', 'type': 'select', 'options': [
                    {'value': 'standard', 'text': 'æ ‡å‡†æ¨¡å¼ (é‡ç”»è´¨)'},
                    {'value': 'fast', 'text': 'æé€Ÿæ¨¡å¼ (é‡é€Ÿåº¦)'}
                ], 'default': 'standard'},
                {'id': 'watermark', 'label': 'æ·»åŠ å®˜æ–¹æ°´å°', 'type': 'checkbox', 'default': False}
            ]
        },
        'seedream-5.0-lite-edit-fal': {
            'provider': 'fal_ai',
            'category': 'multi',
            'endpoint': 'fal-ai/bytedance/seedream/v5/lite/edit',
            'title': 'Seedream 5.0 Lite (Fal)',
            'desc': 'æ”¯æŒæœ€å¤š10å¼ å›¾çš„å¤æ‚ç‰¹å¾èåˆä¸ç¼–è¾‘',
            'params': [
                {'id': 'num_images', 'label': 'ç”Ÿæˆå›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'max_images', 'label': 'æœ€å¤§ç”Ÿæˆå›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'image_size', 'label': 'ç”Ÿæˆå°ºå¯¸ (Size)', 'type': 'select', 'options': [
                    {'value': 'auto_2K', 'text': '2K'},
                    {'value': 'auto_3K', 'text': '3K'},
                    {'value': 'portrait_16_9', 'text': 'ç«–ç‰ˆ 9:16'},
                    {'value': 'portrait_4_3', 'text': 'ç«–ç‰ˆ 3:4'},
                    {'value': 'landscape_16_9', 'text': 'æ¨ªç‰ˆ 16:9'},
                    {'value': 'landscape_4_3', 'text': 'æ¨ªç‰ˆ 4:3'},
                    {'value': 'landscape_16_9', 'text': 'æ¨ªç‰ˆ 16:9'},
                    {'value': 'square_hd', 'text': '1:1 æ­£æ–¹å½¢ HD'},
                    {'value': 'square', 'text': '1:1 æ­£æ–¹å½¢'}
                ], 'default': 'auto_2K'},
                {'id': 'enable_safety_checker', 'label': 'å¯ç”¨å®‰å…¨æ£€æŸ¥', 'type': 'checkbox', 'default': False}

            ]
        },
        'seedream-4.5-edit-fal': {
            'provider': 'fal_ai',
            'category': 'multi',
            'endpoint': 'fal-ai/bytedance/seedream/v4.5/edit',
            'title': 'Seedream 4.5 (Fal)',
            'desc': 'æ”¯æŒæœ€å¤š10å¼ å›¾çš„å¤æ‚ç‰¹å¾èåˆä¸ç¼–è¾‘',
            'params': [
                {'id': 'num_images', 'label': 'ç”Ÿæˆå›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'max_images', 'label': 'æœ€å¤§ç”Ÿæˆå›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'image_size', 'label': 'ç”Ÿæˆå°ºå¯¸ (Size)', 'type': 'select', 'options': [
                    {'value': 'auto_2K', 'text': '2K'},
                    {'value': 'auto_4K', 'text': '4K'},
                    {'value': 'portrait_16_9', 'text': 'ç«–ç‰ˆ 9:16'},
                    {'value': 'portrait_4_3', 'text': 'ç«–ç‰ˆ 3:4'},
                    {'value': 'landscape_16_9', 'text': 'æ¨ªç‰ˆ 16:9'},
                    {'value': 'landscape_4_3', 'text': 'æ¨ªç‰ˆ 4:3'},
                    {'value': 'landscape_16_9', 'text': 'æ¨ªç‰ˆ 16:9'},
                    {'value': 'square_hd', 'text': '1:1 æ­£æ–¹å½¢ HD'},
                    {'value': 'square', 'text': '1:1 æ­£æ–¹å½¢'}
                ], 'default': 'auto_2K'},
                {'id': 'enable_safety_checker', 'label': 'å¯ç”¨å®‰å…¨æ£€æŸ¥', 'type': 'checkbox', 'default': False}

            ]
        },
        'gemini-3-pro-image-preview': {
            'provider': 'google_ai',
            'category': 'multi',  # æ”¯æŒå¤šè¾¾ 14 å¼ å‚è€ƒå›¾
            'endpoint': 'gemini-3-pro-image-preview',
            'title': 'Nano Banana Pro (å®˜æ–¹)',
            'desc': 'ä¸“ä¸ºä¸“ä¸šèµ„äº§ç”Ÿäº§è®¾è®¡ï¼Œé»˜è®¤å¼€å¯æ·±åº¦æ€è€ƒ(Thinking)ï¼Œæ”¯æŒæœ€é«˜4Kç”»è´¨ä¸å¤æ‚è¯­ä¹‰æ¸²æŸ“',
            'params': [
                {'id': 'num_images', 'label': 'ç”Ÿæˆæ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'aspect_ratio', 'label': 'ç”»å¹…æ¯”ä¾‹', 'type': 'select', 'options': [
                    {'value': '1:1', 'text': '1:1 (æ­£æ–¹å½¢)'},
                    {'value': '3:4', 'text': '3:4 (ç«–ç‰ˆ)'},
                    {'value': '4:3', 'text': '4:3 (æ¨ªç‰ˆ)'},
                    {'value': '9:16', 'text': '9:16 (ç«–ç‰ˆ)'},
                    {'value': '16:9', 'text': '16:9 (æ¨ªç‰ˆ)'},
                    {'value': '3:2', 'text': '3:2 (æ¨ªç‰ˆ)'},
                    {'value': '2:3', 'text': '2:3 (ç«–ç‰ˆ)'},
                    {'value': '5:4', 'text': '5:4 (æ¨ªç‰ˆ)'},
                    {'value': '4:5', 'text': '4:5 (ç«–ç‰ˆ)'},
                    {'value': '21:9', 'text': '21:9 (å®½å±)'}
                ], 'default': '9:16'},
                {'id': 'resolution', 'label': 'ç”Ÿæˆåˆ†è¾¨ç‡ (Image Size)', 'type': 'select', 'options': [
                    {'value': '1K', 'text': '1K (1024px)'},
                    {'value': '2K', 'text': '2K (é«˜æ¸…)'},
                    {'value': '4K', 'text': '4K (æè‡´åŸç”»)'}
                ], 'default': '4K'},
                {'id': 'enable_web_search', 'label': 'å¯ç”¨ Google è”ç½‘æœç´¢', 'type': 'checkbox', 'default': False, 'help_text': 'å¼€å¯åï¼Œå¯è®©æ¨¡å‹æ ¹æ®æœ€æ–°èµ„è®¯ã€å¤©æ°”æˆ–æœåˆ°çš„å›¾ç‰‡æ¥ä½œä¸ºç”Ÿæˆä¾æ®ã€‚'}
            ]
        },
        'gemini-2.5-flash-image': {
            'provider': 'google_ai',
            'category': 'multi', # å®˜æ–¹å»ºè®®æœ€å¤š 3 å¼ å‚è€ƒå›¾
            'endpoint': 'gemini-2.5-flash-image',
            'title': 'Nano Banana Flash (å®˜æ–¹)',
            'desc': 'ä¸»æ‰“æé€Ÿç”Ÿæˆï¼Œå›ºå®š 1K åˆ†è¾¨ç‡ï¼Œä¸“ä¸ºé«˜ååã€ä½å»¶è¿Ÿä»»åŠ¡ä¼˜åŒ–',
            'params': [
                {'id': 'num_images', 'label': 'ç”Ÿæˆæ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'aspect_ratio', 'label': 'ç”»å¹…æ¯”ä¾‹', 'type': 'select', 'options': [
                    {'value': '1:1', 'text': '1:1 (æ­£æ–¹å½¢)'},
                    {'value': '3:4', 'text': '3:4 (ç«–ç‰ˆ)'},
                    {'value': '4:3', 'text': '4:3 (æ¨ªç‰ˆ)'},
                    {'value': '9:16', 'text': '9:16 (ç«–ç‰ˆ)'},
                    {'value': '16:9', 'text': '16:9 (æ¨ªç‰ˆ)'},
                    {'value': '3:2', 'text': '3:2 (æ¨ªç‰ˆ)'},
                    {'value': '2:3', 'text': '2:3 (ç«–ç‰ˆ)'},
                    {'value': '5:4', 'text': '5:4 (æ¨ªç‰ˆ)'},
                    {'value': '4:5', 'text': '4:5 (ç«–ç‰ˆ)'},
                    {'value': '21:9', 'text': '21:9 (å®½å±)'}
                ], 'default': '9:16'}
                # æ³¨æ„ï¼š2.5 Flash ä»…æ”¯æŒ 1024pxï¼Œå› æ­¤ä¸æš´éœ² resolution é€‰æ‹©ä¸‹æ‹‰æ¡†
                # æ³¨æ„ï¼š2.5 Flash ä¸æ”¯æŒ thinking_level æ§åˆ¶
            ]
        },
        'gemini-3.1-flash-image-preview': {
            'provider': 'google_ai',
            'category': 'multi',  # æ”¹ä¸º multiï¼Œå› ä¸ºå®ƒåŸç”Ÿæ”¯æŒå¤šè¾¾ 14 å¼ å«å›¾
            'endpoint': 'gemini-3.1-flash-image-preview',
            'title': 'Nano Banana 2 (å®˜æ–¹)',
            'desc': 'æ”¯æŒæœ€é«˜ 4K ç”»è´¨ã€å¤šå›¾èåˆã€è”ç½‘æœç´¢åŠæ·±åº¦æ¨ç†çš„ç»ˆæç”Ÿå›¾æ¨¡å‹',
            'params': [
                {'id': 'aspect_ratio', 'label': 'ç”»å¹…æ¯”ä¾‹', 'type': 'select', 'options': [
                    {'value': '1:1', 'text': '1:1 (æ­£æ–¹å½¢)'},
                    {'value': '3:4', 'text': '3:4 (ç«–ç‰ˆ)'},
                    {'value': '4:3', 'text': '4:3 (æ¨ªç‰ˆ)'},
                    {'value': '9:16', 'text': '9:16 (ç«–ç‰ˆ)'},
                    {'value': '16:9', 'text': '16:9 (æ¨ªç‰ˆ)'},
                    {'value': '21:9', 'text': '21:9 (å®½å±)'}
                ], 'default': '9:16'},
                {'id': 'resolution', 'label': 'ç”Ÿæˆåˆ†è¾¨ç‡ (Image Size)', 'type': 'select', 'options': [
                    {'value': '1K', 'text': '1K (æé€Ÿ)'},
                    {'value': '2K', 'text': '2K (é«˜æ¸…)'},
                    {'value': '4K', 'text': '4K (åŸç”»)'}
                ], 'default': '4K'},
                {'id': 'thinking_level', 'label': 'æ¨¡å‹æ€è€ƒæ·±åº¦', 'type': 'select', 'options': [
                    {'value': 'minimal', 'text': 'Minimal (å¸¸è§„é€Ÿåº¦)'},
                    {'value': 'High', 'text': 'High (æ·±åº¦æ„å›¾ä¸é€»è¾‘åˆ†æ)'}
                ], 'default': 'minimal', 'help_text': 'é€‰æ‹© High ä¼šå¢åŠ ç”Ÿæˆæ—¶é—´ï¼Œä½†åœ¨å¤„ç†å¤æ‚æç¤ºè¯ï¼ˆå¦‚å¤šé‡å…‰å½±ã€ç²¾å‡†æ–‡å­—æ¸²æŸ“ã€å¤æ‚çš„ç©ºé—´ä½ç½®å…³ç³»ï¼‰æ—¶æ•ˆæœæ›´å¥½ã€‚'},
                {'id': 'enable_web_search', 'label': 'å¯ç”¨ Google è”ç½‘æœç´¢', 'type': 'checkbox', 'default': False, 'help_text': 'å¼€å¯åï¼Œå¯è®©æ¨¡å‹æ ¹æ®æœ€æ–°èµ„è®¯ã€å¤©æ°”æˆ–æœåˆ°çš„å›¾ç‰‡æ¥ä½œä¸ºç”Ÿæˆä¾æ®ã€‚'}
            ]
        },
        'nano-banana-2-edit-fal': {
            'provider': 'fal_ai',
            'category': 'multi',
            'endpoint': 'fal-ai/nano-banana-2/edit',
            'title': 'Nano Banana 2(Fal)',
            'desc': 'æ”¯æŒå¤šå›¾èåˆï¼Œé€‚åˆåˆ›æ„ç¼–è¾‘åœºæ™¯',
            'params': [
                {'id': 'num_images', 'label': 'ç”Ÿæˆå›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'aspect_ratio', 'label': 'ç”»å¹…æ¯”ä¾‹', 'type': 'select', 'options': [
                    {'value': 'auto', 'text': 'æ™ºèƒ½éšæœº'},
                    {'value': '21:9', 'text': '21:9 (æ¨ªç‰ˆ)'},
                    {'value': '16:9', 'text': '16:9 (æ¨ªç‰ˆ)'},
                    {'value': '3:2', 'text': '3:2 (æ¨ªç‰ˆ)'},
                    {'value': '4:3', 'text': '4:3 (æ¨ªç‰ˆ)'},
                    {'value': '5:4', 'text': '5:4 (æ¨ªç‰ˆ)'},
                    {'value': '1:1', 'text': '1:1 (æ­£æ–¹)'},
                    {'value': '4:5', 'text': '4:5 (ç«–ç‰ˆ)'},
                    {'value': '3:4', 'text': '3:4 (ç«–ç‰ˆ)'},
                    {'value': '2:3', 'text': '2:3 (ç«–ç‰ˆ)'},
                    {'value': '9:16', 'text': '9:16 (ç«–ç‰ˆ)'},
                ], 'default': '9:16'},
                {'id': 'output_format', 'label': 'è¾“å‡ºæ ¼å¼', 'type': 'select', 'options': [
                    {'value': 'png', 'text': 'PNG (é»˜è®¤)'},
                    {'value': 'jpeg', 'text': 'jpeg'}
                ], 'default': 'png'},
                {'id': 'safety_tolerance', 'label': 'å®‰å…¨æ£€æŸ¥ä¸¥æ ¼åº¦', 'type': 'range', 
                	'min': 1, 
                	'max': 6, 
                	'step': 1, 
                	'default': 6,
                	'help_text': "æ•°å€¼è¶Šä½è¶Šä¸¥æ ¼ï¼Œè¿‡ä½å¯èƒ½å¯¼è‡´è¿‡åº¦è¿‡æ»¤"
                },
                {'id': 'resolution', 'label': 'ç”Ÿæˆåˆ†è¾¨ç‡', 
                	'type': 'select', 
                	'options': [
                    	{'value': "0.5K", "text": "0.5K"},
                    	{'value': "1K", "text": "1K"},
                    	{'value': "2K", "text": "2K"},
                        {'value': "4K", "text": "4K"},
                	], 
                	'default': "1K"
                },
                # {'id':'limit_generations','label':'é™åˆ¶ç”Ÿæˆæ•°é‡','type':'checkbox','default':True,'help_text':'å¯ç”¨åå°†ä¸¥æ ¼é™åˆ¶ç”Ÿæˆæ•°é‡ï¼Œç¡®ä¿ä¸ä¼šè¶…è¿‡è®¾å®šçš„æ•°é‡ï¼Œé€‚åˆèµ„æºæœ‰é™çš„ç¯å¢ƒ'},
                {'id':'enable_web_search','label':'å¯ç”¨ç½‘ç»œæœç´¢','type':'checkbox','default':False,'help_text':'å¯ç”¨åå°†å¯ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½ï¼Œä»¥è·å–æ›´ä¸°å¯Œçš„æç¤ºè¯å†…å®¹ï¼Œå¯èƒ½ä¼šå¢åŠ ç”Ÿæˆæ—¶é—´ï¼Œé€‚åˆéœ€è¦æ›´ä¸°å¯Œè¯­ä¹‰ç†è§£çš„åœºæ™¯'},

            ]
        },
        'nano-banana-pro-edit-fal': {
            'provider': 'fal_ai',
            'category': 'multi',
            'endpoint': 'fal-ai/nano-banana-pro/edit',
            'title': 'Nano Banana Pro(Fal)',
            'desc': 'æ”¯æŒå¤šå›¾èåˆï¼Œé€‚åˆåˆ›æ„ç¼–è¾‘åœºæ™¯',
            'params': [
                {'id': 'num_images', 'label': 'ç”Ÿæˆå›¾æ•°é‡', 'type': 'range', 'min': 1, 'max': 4, 'step': 1, 'default': 1},
                {'id': 'aspect_ratio', 'label': 'ç”»å¹…æ¯”ä¾‹', 'type': 'select', 'options': [
                    {'value': 'auto', 'text': 'æ™ºèƒ½éšæœº'},
                    {'value': '21:9', 'text': '21:9 (æ¨ªç‰ˆ)'},
                    {'value': '16:9', 'text': '16:9 (æ¨ªç‰ˆ)'},
                    {'value': '3:2', 'text': '3:2 (æ¨ªç‰ˆ)'},
                    {'value': '4:3', 'text': '4:3 (æ¨ªç‰ˆ)'},
                    {'value': '5:4', 'text': '5:4 (æ¨ªç‰ˆ)'},
                    {'value': '1:1', 'text': '1:1 (æ­£æ–¹)'},
                    {'value': '4:5', 'text': '4:5 (ç«–ç‰ˆ)'},
                    {'value': '3:4', 'text': '3:4 (ç«–ç‰ˆ)'},
                    {'value': '2:3', 'text': '2:3 (ç«–ç‰ˆ)'},
                    {'value': '9:16', 'text': '9:16 (ç«–ç‰ˆ)'},
                ], 'default': '9:16'},
                {'id': 'output_format', 'label': 'è¾“å‡ºæ ¼å¼', 'type': 'select', 'options': [
                    {'value': 'png', 'text': 'PNG (é»˜è®¤)'},
                    {'value': 'jpeg', 'text': 'jpeg'}
                ], 'default': 'png'},
                {'id': 'safety_tolerance', 'label': 'å®‰å…¨æ£€æŸ¥ä¸¥æ ¼åº¦', 'type': 'range', 
                	'min': 1, 
                	'max': 6, 
                	'step': 1, 
                	'default': 6,
                	'help_text': "æ•°å€¼è¶Šä½è¶Šä¸¥æ ¼ï¼Œè¿‡ä½å¯èƒ½å¯¼è‡´è¿‡åº¦è¿‡æ»¤"
                },
                {'id': 'resolution', 'label': 'ç”Ÿæˆåˆ†è¾¨ç‡', 
                	'type': 'select', 
                	'options': [
                    	{'value': "0.5K", "text": "0.5K"},
                    	{'value': "1K", "text": "1K"},
                    	{'value': "2K", "text": "2K"},
                        {'value': "4K", "text": "4K"},
                	], 
                	'default': "1K"
                },
                # {'id':'limit_generations','label':'é™åˆ¶ç”Ÿæˆæ•°é‡','type':'checkbox','default':True,'help_text':'å¯ç”¨åå°†ä¸¥æ ¼é™åˆ¶ç”Ÿæˆæ•°é‡ï¼Œç¡®ä¿ä¸ä¼šè¶…è¿‡è®¾å®šçš„æ•°é‡ï¼Œé€‚åˆèµ„æºæœ‰é™çš„ç¯å¢ƒ'},
                {'id':'enable_web_search','label':'å¯ç”¨ç½‘ç»œæœç´¢','type':'checkbox','default':False,'help_text':'å¯ç”¨åå°†å¯ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½ï¼Œä»¥è·å–æ›´ä¸°å¯Œçš„æç¤ºè¯å†…å®¹ï¼Œå¯èƒ½ä¼šå¢åŠ ç”Ÿæˆæ—¶é—´ï¼Œé€‚åˆéœ€è¦æ›´ä¸°å¯Œè¯­ä¹‰ç†è§£çš„åœºæ™¯'},

            ]
        },
    }
}

# ==========================================
# è¾…åŠ©å‡½æ•°
# ==========================================
def get_tags_bar_data():
    """
    ã€è‡ªæ„ˆç‰ˆã€‘è·å–æ ‡ç­¾æ æ•°æ®ï¼š
    è‡ªåŠ¨æ‰«æå®é™…ä½œå“ä¸­ç”¨åˆ°çš„ model_infoï¼Œå¦‚æœå‘ç°æ²¡æœ‰æ³¨å†Œåœ¨ AIModel è¡¨é‡Œçš„æ¨¡å‹ï¼Œè‡ªåŠ¨è¡¥é½ã€‚
    ç»å¯¹ä¸ä¼šå†å‘ç”Ÿæ¨¡å‹æ ‡ç­¾ä¸¢å¤±çš„é—®é¢˜ã€‚
    """
    from django.db.models import Count
    
    # 1. ç»Ÿè®¡ä½œå“è¡¨ä¸­å„æ¨¡å‹çš„ä½¿ç”¨æ¬¡æ•° (ä»¥å®é™…ä½œå“ä¸ºå‡†)
    model_stats = PromptGroup.objects.values('model_info').annotate(
        use_count=Count('id')
    ).filter(use_count__gt=0)
    
    final_bar = []
    # è·å–ç›®å‰ AIModel è¡¨é‡Œå·²ç»æ³¨å†Œçš„åå­—
    registered_models = list(AIModel.objects.values_list('name', flat=True))
    
    # 2. æ„é€ æ¨¡å‹ Tab æ•°æ®
    for stat in model_stats:
        m_name = stat['model_info']
        if not m_name: 
            continue
            
        # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šå¦‚æœå‘ç°ä½œå“é‡Œç”¨åˆ°äº†æŸä¸ªæ¨¡å‹ï¼Œä½† AIModel è¡¨é‡Œæ²¡æœ‰ï¼Œç«‹åˆ»è‡ªåŠ¨æ³¨å†Œï¼
        if m_name not in registered_models:
            AIModel.objects.get_or_create(name=m_name)
            registered_models.append(m_name) # åŠ å…¥åˆ—è¡¨ï¼Œç¡®ä¿ä¸‹ä¸€æ­¥èƒ½æŠŠæ™®é€šæ ‡ç­¾é‡Œçš„åŒåæ’é™¤æ‰
            
        final_bar.append({
            'name': m_name,
            'use_count': stat['use_count'],
            'is_model': 1  # æ ‡è®°ä¸ºæ¨¡å‹ï¼Œæ’åœ¨é¦–é¡µé¡¶éƒ¨
        })

    # 3. è·å–å‰©ä½™çš„æ™®é€šæ ‡ç­¾ (æ’é™¤æ‰æ‰€æœ‰çš„æ¨¡å‹å)
    tags = Tag.objects.exclude(name__in=registered_models).annotate(
        use_count=Count('promptgroup')
    ).filter(use_count__gt=0).order_by('-use_count')

    for t in tags:
        final_bar.append({
            'name': t.name,
            'use_count': t.use_count,
            'is_model': 2  # æ ‡è®°ä¸ºæ™®é€šæ ‡ç­¾ï¼Œæ’åœ¨ä¾§è¾¹æ 
        })

    # 4. æ’åºè¿”å›ï¼šå…ˆæŒ‰åˆ†ç±»(æ¨¡å‹åœ¨å‰)ï¼Œå†æŒ‰ä½¿ç”¨æ¬¡æ•°é™åº
    final_bar.sort(key=lambda x: (x['is_model'], -x['use_count']))
    
    return final_bar

def generate_diff_html(base_text, compare_text):
    """
    æ¯”è¾ƒ compare_text (å…¶ä»–ç‰ˆæœ¬) ç›¸å¯¹äº base_text (å½“å‰ç‰ˆæœ¬) çš„å·®å¼‚ã€‚
    åªè¿”å›å·®å¼‚éƒ¨åˆ†çš„ HTMLã€‚
    """
    if base_text is None: base_text = ""
    if compare_text is None: compare_text = ""
    
    def parse_tags_to_dict(text):
        parts = re.split(r'[,\uff0c\n]+', text)
        return {p.strip().lower(): p.strip() for p in parts if p.strip()}

    base_map = parse_tags_to_dict(base_text)
    comp_map = parse_tags_to_dict(compare_text)
    
    base_keys = set(base_map.keys())
    comp_keys = set(comp_map.keys())
    
    added_keys = comp_keys - base_keys
    removed_keys = base_keys - comp_keys
    
    if not added_keys and not removed_keys:
        return '<span class="no-diff">æ— æç¤ºè¯å·®å¼‚</span>'
    
    html_parts = []
    
    for k in added_keys:
        val = comp_map[k]
        display_val = (val[:20] + '..') if len(val) > 20 else val
        html_parts.append(
            f'<span class="diff-tag diff-add" title="ç›¸å¯¹äºå½“å‰ç‰ˆæœ¬ï¼Œæ­¤å¤„æ–°å¢äº†: {val}">'
            f'<i class="bi bi-plus"></i>{display_val}</span>'
        )
        
    for k in removed_keys:
        val = base_map[k]
        display_val = (val[:20] + '..') if len(val) > 20 else val
        html_parts.append(
            f'<span class="diff-tag diff-rem" title="ç›¸å¯¹äºå½“å‰ç‰ˆæœ¬ï¼Œæ­¤å¤„ç§»é™¤äº†: {val}">'
            f'<i class="bi bi-dash"></i>{display_val}</span>'
        )
        
    return "".join(html_parts)

def generate_smart_title(prompt_text):
    """
    æ™ºèƒ½æ¦‚æ‹¬æ ‡é¢˜ï¼šä¼˜å…ˆå°è¯•æœ¬åœ°å¤§æ¨¡å‹ï¼Œå…œåº•ä½¿ç”¨æ­£åˆ™æˆªå–ã€‚
    """
    if not prompt_text:
        return "AI ç‹¬ç«‹åˆ›ä½œ"

    # 1. å°è¯•è°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹ (å¦‚æœä½ åœ¨ ai_utils é‡Œå†™äº†çš„è¯)
    try:
        from .ai_utils import generate_title_with_local_llm
        ai_title = generate_title_with_local_llm(prompt_text)
        if ai_title:
            # ã€æ—¥å¿—æç¤ºã€‘ï¼šå¤§æ¨¡å‹æˆåŠŸ
            print(f"âœ¨ [æ ‡é¢˜ç”Ÿæˆ] æˆåŠŸä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹æ¦‚æ‹¬: {ai_title}")
            return ai_title
        else:
            print("âš ï¸ [æ ‡é¢˜ç”Ÿæˆ] å¤§æ¨¡å‹è¿”å›ä¸ºç©ºï¼Œå‡†å¤‡é™çº§...")
    except Exception as e:
        # ã€æ—¥å¿—æç¤ºã€‘ï¼šå¤§æ¨¡å‹å¼‚å¸¸
        print(f"âŒ [æ ‡é¢˜ç”Ÿæˆ] å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥æˆ–æœªåŠ è½½ï¼ŒåŸå› : {e}")
        pass

    # 2. é™çº§å…œåº•æ–¹æ¡ˆ (æ­£åˆ™è¡¨è¾¾å¼æœ¬åœ°æ¸…æ´—ä¸æˆªå–)
    # ã€æ—¥å¿—æç¤ºã€‘ï¼šè§¦å‘å…œåº•
    print(f"ğŸ”€ [æ ‡é¢˜ç”Ÿæˆ] è§¦å‘æ­£åˆ™å…œåº•æœºåˆ¶...")
    clean_text = re.sub(r'--[a-zA-Z0-9\-]+\s+[\d\.]+', '', prompt_text)
    clean_text = re.sub(r'<[^>]+>', '', clean_text)
    
    parts = re.split(r'[,ï¼Œ.ã€‚\n;ï¼›|]', clean_text)
    parts = [p.strip() for p in parts if p.strip()]

    title = ""
    for part in parts:
        # ====================
        # ä¿®æ”¹åï¼šæ‰©å……é»‘åå•ï¼Œè¿‡æ»¤æ‰å¸¸è§çš„æ•°é‡è¯ã€é•œå¤´è¯å’Œæ¸²æŸ“è¯
        # ====================
        ignore_pattern = r'^(a|an|the|1girl|1boy|solo|masterpiece|best quality|high quality|highres|ultra-detailed|8k|4k|photorealistic|realistic|3d|cg|render|octane|unreal engine|film grain|lomo|ccd)\s+'
        part = re.sub(ignore_pattern, '', part, flags=re.IGNORECASE).strip()
        
        # è¿‡æ»¤æ‰çº¯è‹±æ–‡æ•°å­—çš„çŸ­æ ‡ç­¾ï¼ˆæ¯”å¦‚å•çº¯çš„é•œå¤´å‹å·ï¼‰
        if not part or re.match(r'^[a-zA-Z0-9\-\s]+$', part) and len(part) < 5: 
            continue

        if not title:
            title = part
        else:
            if len(title) + len(part) + 1 <= 28:
                title += f"ï¼Œ{part}"
            else:
                break

    if title:
        title = title[0].upper() + title[1:]
        # ã€æ—¥å¿—æç¤ºã€‘ï¼šæ­£åˆ™æˆªå–æˆåŠŸ
        print(f"âœ… [æ ‡é¢˜ç”Ÿæˆ] æ­£åˆ™æˆªå–ç»“æœ: {title}")
        return title

    # ã€æ—¥å¿—æç¤ºã€‘ï¼šè¿æ­£åˆ™éƒ½æ²¡æˆªå‡ºæ¥
    print(f"â„¹ï¸ [æ ‡é¢˜ç”Ÿæˆ] å…œåº•æå–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ‡é¢˜")
    return "AI ç‹¬ç«‹åˆ›ä½œ"
# ==========================================
# è§†å›¾å‡½æ•°
# ==========================================

def home(request):
    queryset = PromptGroup.objects.all()
    query = request.GET.get('q')
    filter_type = request.GET.get('filter')
    search_id = request.GET.get('search_id')

    # === 1. å¤„ç†ä»¥å›¾æœå›¾æäº¤ (POST) -> è½¬ä¸º GET ===
    if request.method == 'POST' and request.FILES.get('search_image'):
        try:
            search_file = request.FILES['search_image']
            similar_images = search_similar_images(search_file, ImageItem.objects.all(), top_k=50)
            
            if not similar_images:
                messages.info(request, "æœªæ‰¾åˆ°ç›¸ä¼¼å›¾ç‰‡")
                return redirect('home')
            
            search_uuid = str(uuid.uuid4())
            cache_data = [{'id': img.id, 'score': getattr(img, 'similarity_score', 0)} for img in similar_images]
            cache_key = f"home_search_{search_uuid}"
            cache.set(cache_key, cache_data, 3600)
            
            return redirect(f"/?search_id={search_uuid}")
                
        except Exception as e:
            print(f"Search error: {e}")
            messages.error(request, "æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
            return redirect('home')

    # === 2. å¤„ç†ä»¥å›¾æœå›¾ç»“æœå±•ç¤º (GET) ===
    if search_id:
        cache_key = f"home_search_{search_id}"
        cached_data = cache.get(cache_key)
        
        if cached_data:
            ids = [item['id'] for item in cached_data]
            id_score_map = {item['id']: item['score'] for item in cached_data}
            
            images_list = list(ImageItem.objects.filter(id__in=ids))
            objects_dict = {img.id: img for img in images_list}
            
            restored_images = []
            for img_id in ids:
                if img_id in objects_dict:
                    obj = objects_dict[img_id]
                    obj.similarity_score = id_score_map.get(img_id, 0)
                    restored_images.append(obj)
            
            tags_bar = get_tags_bar_data()

            if restored_images:
                return render(request, 'gallery/liked_images.html', {
                    'page_obj': restored_images,
                    'search_query': 'å…¨åº“ä»¥å›¾æœå›¾ç»“æœ',
                    'search_mode': 'image',
                    'is_home_search': True,
                    'current_search_id': search_id,
                    'tags_bar': tags_bar
                })
        else:
            messages.warning(request, "æœç´¢ç»“æœå·²è¿‡æœŸï¼Œè¯·é‡æ–°æœç´¢")

    # === å¸¸è§„æ–‡æœ¬æœç´¢ ===
    if query:
        queryset = queryset.filter(
            Q(title__icontains=query) |
            Q(prompt_text__icontains=query) |
            Q(prompt_text_zh__icontains=query) |
            Q(model_info__icontains=query) |       # ã€æ–°å¢ã€‘æ”¯æŒæœæ¨¡å‹
            Q(characters__name__icontains=query) | # ã€æ–°å¢ã€‘æ”¯æŒæœäººç‰©
            Q(tags__name__icontains=query)
        ).distinct()
    
    if filter_type == 'liked':
        queryset = queryset.filter(is_liked=True)

    # === ç‰ˆæœ¬å»é‡ä¸è®¡æ•°é€»è¾‘ ===
    version_counts = {}
    if not query and not filter_type and not search_id:
        # ã€ä¿®æ”¹ã€‘ä½¿ç”¨ Case/When ä¼˜å…ˆè·å– is_main_variant=True çš„ ID
        group_stats = PromptGroup.objects.values('group_id').annotate(
            main_id=Max(Case(When(is_main_variant=True, then='id'), output_field=IntegerField())),
            latest_id=Max('id'),
            count=Count('id')
        )
        final_ids = []
        for s in group_stats:
            # å¦‚æœè®¾å®šäº†ä¸»ç‰ˆæœ¬(main_id)ï¼Œå°±ç”¨å®ƒï¼›å¦åˆ™ç”¨æœ€æ–°çš„(latest_id)
            target_id = s['main_id'] if s['main_id'] else s['latest_id']
            final_ids.append(target_id)
            version_counts[target_id] = s['count']
        queryset = queryset.filter(id__in=final_ids)

    tags_bar = get_tags_bar_data()
    paginator = Paginator(queryset, 12)
    page_number = request.GET.get('page')
    page = paginator.get_page(page_number)
    page_obj = paginator.get_page(page_number)
    page_range = page.paginator.get_elided_page_range(page.number, on_each_side=2, on_ends=1)
    total_groups_count = PromptGroup.objects.values('group_id').distinct().count()

    for group in page_obj:
        group.version_count = version_counts.get(group.id, 0)

    return render(request, 'gallery/home.html', {
        'groups': page,
        'page_obj': page_obj,
        'page_range': page_range,
        'search_query': query,
        'current_filter': filter_type,
        'tags_bar': tags_bar,
        'total_groups_count': total_groups_count,
    })


def liked_images_gallery(request):
    queryset = ImageItem.objects.filter(is_liked=True).order_by('-id')
    search_mode = 'text'
    query_text = request.GET.get('q')
    search_id = request.GET.get('search_id') 
    
    if request.method == 'POST' and request.FILES.get('image_query'):
        try:
            uploaded_file = request.FILES['image_query']
            results = search_similar_images(uploaded_file, queryset) 
            
            search_uuid = str(uuid.uuid4())
            cache_data = [{'id': img.id, 'score': getattr(img, 'similarity_score', 0)} for img in results]
            
            cache_key = f"liked_search_{search_uuid}"
            cache.set(cache_key, cache_data, 3600)
            
            return redirect(f"/liked-images/?search_id={search_uuid}")
            
        except Exception as e:
            messages.error(request, "æœç´¢å¤±è´¥")
            return redirect('liked_images_gallery')

    if search_id:
        cache_key = f"liked_search_{search_id}"
        cached_data = cache.get(cache_key)
        
        if cached_data:
            ids = [item['id'] for item in cached_data]
            id_score_map = {item['id']: item['score'] for item in cached_data}
            
            images_list = list(ImageItem.objects.filter(id__in=ids))
            objects_dict = {img.id: img for img in images_list}
            
            queryset = []
            for img_id in ids:
                if img_id in objects_dict:
                    obj = objects_dict[img_id]
                    obj.similarity_score = id_score_map.get(img_id, 0)
                    queryset.append(obj)
            
            search_mode = 'image'
            query_text = "æŒ‰å›¾ç‰‡æœç´¢ç»“æœ"
        else:
             messages.warning(request, "æœç´¢å·²è¿‡æœŸ")
    
    elif query_text:
        queryset = queryset.filter(
            Q(group__title__icontains=query_text) |
            Q(group__prompt_text__icontains=query_text) |
            Q(group__model_info__icontains=query_text) |       # ã€æ–°å¢ã€‘æ”¯æŒæœæ¨¡å‹
            Q(group__characters__name__icontains=query_text) | # ã€æ–°å¢ã€‘æ”¯æŒæœäººç‰©
            Q(group__tags__name__icontains=query_text)
        ).distinct()
    
    tags_bar = get_tags_bar_data()
    paginator = Paginator(queryset, 20)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    return render(request, 'gallery/liked_images.html', {
        'page_obj': page_obj,
        'search_query': query_text,
        'search_mode': search_mode,
        'is_home_search': False,
        'current_search_id': search_id,
        'tags_bar': tags_bar
    })


def detail(request, pk):
    group = get_object_or_404(
        PromptGroup.objects.prefetch_related(
            'tags', 
            Prefetch('images', queryset=ImageItem.objects.order_by('-id')),
            'references'
        ), 
        pk=pk
    )
    # === ä¸Šä¸€ç¯‡/ä¸‹ä¸€ç¯‡ å¯¼èˆªé€»è¾‘ (Context Aware) ===
    # è·å–ä¸Šä¸‹æ–‡å‚æ•°
    query = request.GET.get('q')
    filter_type = request.GET.get('filter')
    
    # æ„é€ åŸºç¡€æŸ¥è¯¢é›† (Nav QuerySet)
    nav_qs = PromptGroup.objects.all()
    
    # 1. å¤åˆ»é¦–é¡µçš„æœç´¢é€»è¾‘
    if query:
        nav_qs = nav_qs.filter(
            Q(title__icontains=query) |
            Q(prompt_text__icontains=query) |
            Q(prompt_text_zh__icontains=query) |
            Q(model_info__icontains=query) |       # ã€æ–°å¢ã€‘æ”¯æŒæœæ¨¡å‹
            Q(characters__name__icontains=query) | # ã€æ–°å¢ã€‘æ”¯æŒæœäººç‰©
            Q(tags__name__icontains=query)
        ).distinct()
        
    # 2. å¤åˆ»é¦–é¡µçš„ç­›é€‰é€»è¾‘
    if filter_type == 'liked':
        nav_qs = nav_qs.filter(is_liked=True)
        
    # 3. é»˜è®¤æ¨¡å¼ä¸‹çš„å»é‡é€»è¾‘ (ä»…åœ¨æ— æœç´¢ã€æ— ç­›é€‰æ—¶åº”ç”¨)
    # å¦‚æœç”¨æˆ·åœ¨æœç´¢æ¨¡å¼ä¸‹ï¼Œå¯èƒ½å¸Œæœ›çœ‹åˆ°æ‰€æœ‰å‘½ä¸­çš„ç‰ˆæœ¬ï¼Œæ‰€ä»¥æœç´¢æ—¶ä¸è¿›è¡Œå»é‡
    is_default_view = (not query and not filter_type)
    
    if is_default_view:
        # è·å–ä»£è¡¨IDåˆ—è¡¨ (ä¸»ç‰ˆæœ¬ or æœ€æ–°ç‰ˆæœ¬)
        group_stats = PromptGroup.objects.values('group_id').annotate(
            main_id=Max(Case(When(is_main_variant=True, then='id'), output_field=IntegerField())),
            latest_id=Max('id')
        )
        target_ids = [ (s['main_id'] or s['latest_id']) for s in group_stats ]
        nav_qs = nav_qs.filter(id__in=target_ids)

    # 4. è®¡ç®— ä¸Šä¸€ç¯‡ (Previous = IDæ›´çš„å¤§ = æ›´æ™šåˆ›å»º)
    # å¦‚æœæ˜¯é»˜è®¤è§†å›¾ï¼Œé¢å¤–æ’é™¤åŒ Group çš„ ID (è™½ç„¶ dedupe ç†è®ºä¸Šå·²å¤„ç†ï¼ŒåŠ ä¸€å±‚ä¿é™©)
    prev_qs = nav_qs.filter(id__gt=pk)
    if is_default_view:
        prev_qs = prev_qs.exclude(group_id=group.group_id)
    prev_group = prev_qs.order_by('id').first() # æ‰¾æ¯”å½“å‰pkå¤§çš„é‡Œé¢æœ€å°çš„é‚£ä¸ª
    
    # 5. è®¡ç®— ä¸‹ä¸€ç¯‡ (Next = IDæ›´å° = æ›´æ—©åˆ›å»º)
    next_qs = nav_qs.filter(id__lt=pk)
    if is_default_view:
        next_qs = next_qs.exclude(group_id=group.group_id)
    next_group = next_qs.order_by('-id').first() # æ‰¾æ¯”å½“å‰pkå°çš„é‡Œé¢æœ€å¤§çš„é‚£ä¸ª

    # æ‹†åˆ†å›¾ç‰‡å’Œè§†é¢‘
    all_items = group.images.all()
    images_list = [item for item in all_items if not item.is_video]
    videos_list = [item for item in all_items if item.is_video]
    
    tags_list = list(group.tags.all())
    chars_list = list(group.characters.all()) if hasattr(group, 'characters') else []
    model_name = group.model_info
    if model_name:
        tags_list.sort(key=lambda t: 0 if t.name == model_name else 1)
    # ã€æ£€æŸ¥ã€‘ï¼šæ„é€ æ··åˆè”æƒ³è¯åº“ (Tag + Character)
    base_tags = Tag.objects.annotate(usage_count=Count('promptgroup')).order_by('-usage_count', 'name')[:500]
    all_tags = list(base_tags)
    
    try:
        # å†è·å–äººç‰©æ ‡ç­¾å¹¶æ··å…¥åˆ—è¡¨
        all_chars = Character.objects.annotate(usage_count=Count('promptgroup')).order_by('-usage_count', 'name')[:200]
        existing_names = {t.name for t in all_tags}
        for c in all_chars:
            if c.name not in existing_names:
                all_tags.append(c) # åªè¦æ¨¡å‹æœ‰ .name å±æ€§ï¼Œå‰ç«¯ datalist å°±èƒ½æ­£å¸¸æ˜¾ç¤º
    except Exception:
        pass
    # all_tags = Tag.objects.annotate(usage_count=Count('promptgroup')).order_by('-usage_count', 'name')[:500]

    siblings_qs = PromptGroup.objects.filter(
        group_id=group.group_id
    ).exclude(pk=group.pk).order_by('-created_at')
    
    siblings = []
    current_prompt = group.prompt_text or ""
    
    for sib in siblings_qs:
        sib_prompt = sib.prompt_text or ""
        sib.diff_html = generate_diff_html(current_prompt, sib_prompt)
        siblings.append(sib)

    # 1. è·å–å½“å‰å¡ç‰‡çš„æ ‡ç­¾ ID åˆ—è¡¨
    tag_ids = group.tags.values_list('id', flat=True)

    if not tag_ids:
        related_groups = []
    else:
        # 2. æ ¸å¿ƒæ”¹è¿›é€»è¾‘ï¼š
        related_groups = PromptGroup.objects.filter(
            tags__id__in=tag_ids                 # åŒ¹é…æ‹¥æœ‰ç›¸åŒæ ‡ç­¾çš„ä½œå“
        ).exclude(
            group_id=group.group_id              # æ’é™¤æ‰å½“å‰ä½œå“åŠå…¶å˜ä½“ç³»åˆ—
        ).annotate(
            same_tag_count=Count('tags')         # ã€å…³é”®ã€‘ç»Ÿè®¡æ¯å¼ å€™é€‰å¡ç‰‡ä¸å½“å‰å¡ç‰‡é‡åˆçš„æ ‡ç­¾æ•°é‡
        ).order_by(
            '-same_tag_count',                   # 1. æ ‡ç­¾é‡åˆè¶Šå¤šï¼ˆè¶Šåƒï¼‰çš„æ’è¶Šå‰é¢
            '?'                                  # 2. åœ¨ç›¸ä¼¼åº¦ç›¸åŒæ—¶éšæœºæ‰“ä¹±ï¼ˆæ‰“ç ´â€œæ°¸è¿œä¸€æ ·â€çš„åƒµå±€ï¼‰
        ).distinct()[:4]
    
    tags_bar = get_tags_bar_data()

    return render(request, 'gallery/detail.html', {
        'group': group,
        'sorted_tags': tags_list,
        'chars_list': chars_list,
        'all_tags': all_tags,
        'siblings': siblings,
        'related_groups': related_groups,
        'tags_bar': tags_bar,
        'search_query': request.GET.get('q'),
        'images_list': images_list,
        'videos_list': videos_list,
        'prev_group': prev_group,
        'next_group': next_group,
    })


def upload(request):
    if request.method == 'POST':
        prompt_text = request.POST.get('prompt_text', '')
        prompt_text_zh = request.POST.get('prompt_text_zh', '')
        negative_prompt = request.POST.get('negative_prompt', '')
        title = request.POST.get('title', '') or 'æœªå‘½åç»„'
        model_id = request.POST.get('model_info')

        # ã€æ–°å¢ã€‘ï¼šæ™ºèƒ½æ¦‚æ‹¬ä¸Šä¼ é¡µçš„æ ‡é¢˜
        if title == 'æœªå‘½åç»„' and prompt_text:
            title = generate_smart_title(prompt_text)
            print(f"DEBUG: ä¸Šä¼ é¡µç”Ÿæˆäº†æ™ºèƒ½æ ‡é¢˜ -> {title}")
        
        model_name_str = ""
        if model_id:
            try:
                model_instance = AIModel.objects.get(id=model_id)
                model_name_str = model_instance.name
            except AIModel.DoesNotExist:
                pass

        group = PromptGroup.objects.create(
            title=title,
            prompt_text=prompt_text,
            prompt_text_zh=prompt_text_zh,
            negative_prompt=negative_prompt,
            model_info=model_name_str,
        )
        
        selected_tags = request.POST.getlist('tags')
        for tag_val in selected_tags:
            tag_val = tag_val.strip()
            if not tag_val: continue
            if tag_val.isdigit():
                try:
                    group.tags.add(Tag.objects.get(id=int(tag_val)))
                except Tag.DoesNotExist:
                    pass
            else:
                tag, _ = Tag.objects.get_or_create(name=tag_val)
                group.tags.add(tag)
        
        # ã€æ–°å¢ã€‘ï¼šå¸¸è§„ä¸Šä¼ çš„æ¨¡å‹æ ‡ç­¾æ’ä»–æ€§å¤„ç†
        # if model_name_str:
        #     m_tag, _ = Tag.objects.get_or_create(name=model_name_str)
        #     group.tags.add(m_tag)
            
        #     all_model_names = list(AIModel.objects.values_list('name', flat=True))
        #     for tag in group.tags.all():
        #         if tag.name in all_model_names and tag.name != model_name_str:
        #             group.tags.remove(tag)

        source_group_id = request.POST.get('source_group_id')
        print(f"DEBUG: å°è¯•å…‹éš†å‚è€ƒå›¾ï¼ŒSource ID: {source_group_id}") # è°ƒè¯•æ‰“å° 1
        
        if source_group_id:
            try:
                source_group = PromptGroup.objects.get(pk=source_group_id)
                refs = source_group.references.all()
                print(f"DEBUG: æ‰¾åˆ°æºå‚è€ƒå›¾æ•°é‡: {refs.count()}") # è°ƒè¯•æ‰“å° 2
                
                for ref in refs:
                    if ref.image:
                        print(f"DEBUG: æ­£åœ¨å¤åˆ¶å›¾ç‰‡: {ref.image.name}") # è°ƒè¯•æ‰“å° 3
                        
                        # åˆ›å»ºæ–°å¯¹è±¡
                        new_ref = ReferenceItem(group=group)
                        
                        # æ˜¾å¼æ‰“å¼€æ–‡ä»¶ï¼ˆä½¿ç”¨ with è¯­å¥æ›´å®‰å…¨ï¼‰
                        try:
                            # å¿…é¡»ç¡®ä¿æ–‡ä»¶å­˜åœ¨
                            if not ref.image.storage.exists(ref.image.name):
                                print(f"DEBUG: åŸæ–‡ä»¶ä¸å­˜åœ¨äºç£ç›˜: {ref.image.name}")
                                continue

                            with ref.image.open('rb') as f:
                                # è¯»å–å†…å®¹
                                file_content = ContentFile(f.read())
                                # ç”Ÿæˆæ–°æ–‡ä»¶å
                                original_name = os.path.basename(ref.image.name)
                                # ä¿å­˜
                                new_ref.image.save(f"copy_{original_name}", file_content, save=True)
                                print("DEBUG: å¤åˆ¶æˆåŠŸ")
                                
                        except Exception as inner_e:
                            print(f"DEBUG: å¤åˆ¶å•ä¸ªæ–‡ä»¶å¤±è´¥: {inner_e}")
                            # è¿™é‡Œä¸è¦ raiseï¼Œé˜²æ­¢ä¸€å¼ å›¾å¤±è´¥å¯¼è‡´æ•´ä¸ªæµç¨‹å¤±è´¥
                            # ä½†ä¸€å®šè¦æ‰“å°å‡ºæ¥çœ‹æ˜¯ä»€ä¹ˆé”™

            except PromptGroup.DoesNotExist:
                print("DEBUG: æºç»„ ID æœªæ‰¾åˆ°")
        else:
            print("DEBUG: æœªæ¥æ”¶åˆ° source_group_idï¼Œå‰ç«¯å¯èƒ½æœªä¼ é€’")

        created_image_ids = []
        
        direct_files = request.FILES.getlist('upload_images')
        for f in direct_files:
            img_item = ImageItem(group=group, image=f)
            img_item.save()
            created_image_ids.append(img_item.id)

        batch_id = request.POST.get('batch_id')
        server_file_names = request.POST.getlist('selected_files')
        
        if batch_id and server_file_names:
            temp_ids = confirm_upload_images(batch_id, server_file_names, group)
            created_image_ids.extend(temp_ids)
            
        ref_files = request.FILES.getlist('upload_references')
        for rf in ref_files:
            ReferenceItem.objects.create(group=group, image=rf)

        if not created_image_ids:
            pass
        else:
            trigger_background_processing(created_image_ids)
            messages.success(request, f"æˆåŠŸå‘å¸ƒï¼åŒ…å« {len(created_image_ids)} ä¸ªæ–‡ä»¶ï¼Œç³»ç»Ÿæ­£åœ¨åå°å¤„ç†ç´¢å¼•ã€‚")

        is_ajax = request.headers.get('x-requested-with') == 'XMLHttpRequest' or \
                  request.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'

        if is_ajax:
            group.version_count = 1 
            html = render_to_string('gallery/components/home_group_card.html', {
                'group': group,
            }, request=request)
            return JsonResponse({
                'status': 'success',
                'html': html,
                'message': f"æˆåŠŸå‘å¸ƒï¼åŒ…å« {len(created_image_ids)} ä¸ªæ–‡ä»¶"
            })

        return redirect('home')

    else:
        # === GET è¯·æ±‚ï¼šæ¸²æŸ“ä¸Šä¼ é¡µé¢ ===
        batch_id = request.GET.get('batch_id')
        temp_files_preview = []
        
        if batch_id:
            temp_dir = get_temp_dir(batch_id)
            if os.path.exists(temp_dir):
                try:
                    file_names = os.listdir(temp_dir)
                    for name in file_names:
                        full_path = os.path.join(temp_dir, name)
                        if os.path.isfile(full_path):
                            temp_files_preview.append({
                                'name': name, 
                                'url': f"{settings.MEDIA_URL}temp_uploads/{batch_id}/{name}",
                                'size': os.path.getsize(full_path) 
                            })
                except Exception as e:
                    print(f"Error reading temp dir: {e}")
        
        # === ã€æ–°å¢ã€‘å¤„ç† template_id é¢„å¡«å…… ===
        template_id = request.GET.get('template_id')
        initial_data = {}
        source_group = None
        
        if template_id:
            try:
                source_group = PromptGroup.objects.get(pk=template_id)
                initial_data = {
                    'title': source_group.title, # å¯ä»¥é€‰æ‹©åŠ ä¸Š ' (æ–°æ¨¡å‹)' åç¼€
                    'prompt_text': source_group.prompt_text,
                    'prompt_text_zh': source_group.prompt_text_zh,
                    'negative_prompt': source_group.negative_prompt,
                    'tags': source_group.tags.all(),
                    # æ³¨æ„ï¼šä¸é¢„å¡«å…… model_infoï¼Œå¼ºåˆ¶ç”¨æˆ·é€‰æ‹©æ–°æ¨¡å‹
                }
            except PromptGroup.DoesNotExist:
                pass

        form = PromptGroupForm(initial=initial_data)
        existing_titles = PromptGroup.objects.values_list('title', flat=True).distinct().order_by('title')
        all_models = AIModel.objects.all()

        temp_files_json = json.dumps(temp_files_preview)

        return render(request, 'gallery/upload.html', {
            'form': form,
            'existing_titles': existing_titles,
            'all_models': all_models,
            'batch_id': batch_id,
            'temp_files': temp_files_json,
            'source_group': source_group,
        })


@csrf_exempt
def check_duplicates(request):
    """å…¨åº“æŸ¥é‡æ¥å£ (ä¿®å¤ç‰ˆ - ä¿®æ­£ update æŠ¥é”™)"""
    if request.method != 'POST':
        return JsonResponse({'status': 'error', 'message': 'ä»…æ”¯æŒ POST è¯·æ±‚'})

    files = request.FILES.getlist('images')
    if not files:
        return JsonResponse({'status': 'error', 'message': 'æœªæ£€æµ‹åˆ°ä¸Šä¼ æ–‡ä»¶'})

    # 1. åˆ›å»ºä¸´æ—¶ä¿å­˜ç›®å½•
    batch_id = uuid.uuid4().hex
    temp_dir = os.path.join(settings.MEDIA_ROOT, 'temp_uploads', batch_id)
    os.makedirs(temp_dir, exist_ok=True)

    results = []

    try:
        for file in files:
            # 2. ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            file_path = os.path.join(temp_dir, file.name)
            with open(file_path, 'wb+') as destination:
                for chunk in file.chunks():
                    destination.write(chunk)  # ã€ä¿®æ­£ã€‘è¿™é‡Œå¿…é¡»ç”¨ writeï¼Œä¸èƒ½ç”¨ update

            # 3. è®¡ç®—å“ˆå¸Œ (ç¡®ä¿å¼•å…¥äº† calculate_file_hash)
            # æ³¨æ„ï¼šcalculate_file_hash é€šå¸¸éœ€è¦æ–‡ä»¶è·¯å¾„æˆ–æ‰“å¼€çš„æ–‡ä»¶å¯¹è±¡ï¼Œ
            # è¿™é‡Œä¼ å…¥ file_path æ¯”è¾ƒç¨³å¦¥ï¼Œå› ä¸º file å¯¹è±¡æŒ‡é’ˆå¯èƒ½å·²ç»åˆ°åº•äº†
            file_hash = calculate_file_hash(file_path) 
            
            # æ„é€  URL
            relative_path = f"temp_uploads/{batch_id}/{file.name}"
            file_url = f"{settings.MEDIA_URL}{relative_path}"

            # 4. æŸ¥åº“æ¯”å¯¹
            duplicates = ImageItem.objects.filter(image_hash=file_hash)
            
            is_duplicate = duplicates.exists()
            dup_info = []
            
            if is_duplicate:
                for dup in duplicates:
                    dup_info.append({
                        'id': dup.id,
                        'group_id': dup.group.id, # ç¡®ä¿å‰ç«¯ç”¨ group_id è·³è½¬è¯¦æƒ…é¡µ
                        'group_title': dup.group.title,
                        'is_video': dup.is_video,
                        'url': dup.thumbnail.url if dup.thumbnail else dup.image.url
                    })

            results.append({
                'filename': file.name,
                'status': 'duplicate' if is_duplicate else 'pass',
                'url': file_url,
                'thumbnail_url': file_url, # å‰ç«¯å­—æ®µå…¼å®¹
                'duplicates': dup_info
            })
            
    except Exception as e:
        import traceback
        traceback.print_exc() # æ‰“å°è¯¦ç»†é”™è¯¯å †æ ˆåˆ°æ§åˆ¶å°ï¼Œæ–¹ä¾¿è°ƒè¯•
        shutil.rmtree(temp_dir, ignore_errors=True)
        return JsonResponse({'status': 'error', 'message': str(e)})

    return JsonResponse({
        'status': 'success', 
        'batch_id': batch_id, 
        'results': results,
        'has_duplicate': any(r['status'] == 'duplicate' for r in results)
    })

@require_POST
def toggle_like_group(request, pk):
    group = get_object_or_404(PromptGroup, pk=pk)
    group.is_liked = not group.is_liked
    group.save()
    return JsonResponse({'status': 'success', 'is_liked': group.is_liked})

@require_POST
def toggle_like_image(request, pk):
    image = get_object_or_404(ImageItem, pk=pk)
    image.is_liked = not image.is_liked
    image.save()
    return JsonResponse({'status': 'success', 'is_liked': image.is_liked})

def add_images_to_group(request, pk):
    group = get_object_or_404(PromptGroup, pk=pk)
    
    if request.method == 'POST':
        is_ajax = request.headers.get('x-requested-with') == 'XMLHttpRequest' or \
                  request.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'
                  
        try:
            files = request.FILES.getlist('new_images')
            duplicates = []
            uploaded_count = 0
            created_ids = []

            if files:
                for f in files:
                    file_hash = calculate_file_hash(f)
                    # æ£€æŸ¥ç»„å†…æ’é‡
                    existing_img = ImageItem.objects.filter(group=group, image_hash=file_hash).first()
                    
                    if existing_img:
                        duplicates.append({
                            'name': f.name,
                            'existing_group_title': existing_img.group.title,
                            'existing_url': existing_img.image.url
                        })
                    else:
                        img_item = ImageItem(group=group, image=f)
                        img_item.image_hash = file_hash
                        img_item.save()
                        created_ids.append(img_item.id)
                        uploaded_count += 1
            
            if created_ids:
                trigger_background_processing(created_ids)

            if is_ajax:
                # é‡æ–°æŸ¥è¯¢ä»¥ç¡®ä¿æ•°æ®å®Œæ•´
                new_images = ImageItem.objects.filter(id__in=created_ids).order_by('id')
                new_images_data = []
                html_list = []
                
                for img in new_images:
                    # ã€æ ¸å¿ƒä¿®å¤ã€‘ä¸Šä¼ åç«‹å³æ˜¾ç¤ºæ—¶ï¼Œç›´æ¥ä½¿ç”¨åŸå›¾ URLï¼Œé¿å…ç¼©ç•¥å›¾æœªç”Ÿæˆå¯¼è‡´çš„ç™½å›¾
                    # åŸæ¥çš„ try-except é€»è¾‘è™½ç„¶æœ‰å…œåº•ï¼Œä½† ImageKit å¯èƒ½ä¼šè¿”å›ä¸€ä¸ªå­˜åœ¨çš„ç©ºæ–‡ä»¶è·¯å¾„å¯¼è‡´ç™½å›¾
                    safe_url = img.image.url if img.image else ""

                    new_images_data.append({
                        'id': img.pk,
                        'url': img.image.url, 
                        'isLiked': img.is_liked,
                        'is_video': img.is_video,
                        'isVideo': img.is_video 
                    })
                    
                    html = render_to_string('gallery/components/detail_image_card.html', {
                        'img': img, 
                        'force_image_url': safe_url  # å¼ºåˆ¶ä¼ å…¥åŸå›¾ URL
                    }, request=request)
                    html_list.append(html)

                msg = f"æˆåŠŸæ·»åŠ  {uploaded_count} ä¸ªæ–‡ä»¶"
                if duplicates:
                    msg += f"ï¼Œå¿½ç•¥ {len(duplicates)} ä¸ªé‡å¤æ–‡ä»¶"

                return JsonResponse({
                    'status': 'success' if not duplicates else 'warning',
                    'message': msg,
                    'uploaded_count': uploaded_count,
                    'duplicates': duplicates,
                    'new_images_html': html_list,
                    'new_images_data': new_images_data,
                    'type': 'gen'
                })
            
            # é AJAX è¯·æ±‚çš„å›é€€
            if duplicates:
                messages.warning(request, f"æˆåŠŸæ·»åŠ  {uploaded_count} ä¸ªæ–‡ä»¶ï¼Œå¿½ç•¥ {len(duplicates)} ä¸ªé‡å¤æ–‡ä»¶")
            else:
                messages.success(request, f"æˆåŠŸæ·»åŠ  {uploaded_count} ä¸ªæ–‡ä»¶")
        
        except Exception as e:
            if is_ajax:
                return JsonResponse({'status': 'error', 'message': str(e)}, status=500)
            raise e
            
    return redirect('detail', pk=pk)


def add_references_to_group(request, pk):
    group = get_object_or_404(PromptGroup, pk=pk)
    
    if request.method == 'POST':
        is_ajax = request.headers.get('x-requested-with') == 'XMLHttpRequest' or \
                  request.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'

        try:
            files = request.FILES.getlist('new_references')
            new_refs = []
            if files:
                for f in files:
                    ref = ReferenceItem.objects.create(group=group, image=f)
                    new_refs.append(ref)
            
            if is_ajax:
                html_list = []
                for ref in new_refs:
                    html = render_to_string('gallery/components/detail_reference_item.html', {
                        'ref': ref,
                    }, request=request)
                    html_list.append(html)
                
                return JsonResponse({
                    'status': 'success',
                    'message': f"æˆåŠŸæ·»åŠ  {len(new_refs)} ä¸ªå‚è€ƒæ–‡ä»¶",
                    'uploaded_count': len(new_refs),
                    'new_references_html': html_list,
                    'type': 'ref'
                })
        except Exception as e:
            if is_ajax:
                return JsonResponse({'status': 'error', 'message': str(e)}, status=500)
            raise e

    return redirect('detail', pk=pk)


def delete_group(request, pk):
    group = get_object_or_404(PromptGroup, pk=pk)
    if request.method == 'POST':
        is_ajax = request.headers.get('x-requested-with') == 'XMLHttpRequest' or \
                  request.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'

        for img in group.images.all():
            if img.image:
                img.image.delete(save=False)
        for ref in group.references.all():
            if ref.image:
                ref.image.delete(save=False)
        group.delete()
        
        if is_ajax:
            return JsonResponse({'status': 'success', 'type': 'group'})

        messages.success(request, "å·²åˆ é™¤è¯¥ç»„å†…å®¹")
        return redirect('home')
        
    return redirect('detail', pk=pk)


def delete_image(request, pk):
    image_item = get_object_or_404(ImageItem, pk=pk)
    group_pk = image_item.group.pk
    
    if request.method == 'POST':
        is_ajax = request.headers.get('x-requested-with') == 'XMLHttpRequest' or \
                  request.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'
                  
        try:
            image_item.image.delete(save=False)
            image_item.delete()
            
            if is_ajax:
                return JsonResponse({'status': 'success', 'pk': pk})
        except Exception as e:
            if is_ajax:
                return JsonResponse({'status': 'error', 'message': str(e)})
            
    return redirect('detail', pk=group_pk)


def delete_reference(request, pk):
    item = get_object_or_404(ReferenceItem, pk=pk)
    group_pk = item.group.pk
    
    if request.method == 'POST':
        is_ajax = request.headers.get('x-requested-with') == 'XMLHttpRequest' or \
                  request.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'
                  
        try:
            item.image.delete(save=False)
            item.delete()
            
            if is_ajax:
                return JsonResponse({'status': 'success', 'pk': pk})
        except Exception as e:
            if is_ajax:
                return JsonResponse({'status': 'error', 'message': str(e)})
            
    return redirect('detail', pk=group_pk)


@require_POST
def update_group_prompts(request, pk):
    group = get_object_or_404(PromptGroup, pk=pk)
    try:
        data = json.loads(request.body)
        if 'title' in data:
            group.title = data['title']
        if 'prompt_text' in data:
            group.prompt_text = data['prompt_text']
        if 'prompt_text_zh' in data:
            group.prompt_text_zh = data['prompt_text_zh']
        if 'negative_prompt' in data:
            group.negative_prompt = data['negative_prompt']
        if 'model_info' in data:
            group.model_info = data['model_info']
            
        group.save()
        return JsonResponse({'status': 'success'})
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)}, status=400)


@require_POST
def add_tag_to_group(request, pk):
    group = get_object_or_404(PromptGroup, pk=pk)
    try:
        data = json.loads(request.body)
        tag_name = data.get('tag_name', '').strip()
        if not tag_name:
            return JsonResponse({'status': 'error', 'message': 'æ ‡ç­¾åä¸èƒ½ä¸ºç©º'})
        
        # ã€æ™ºèƒ½åˆ†æµé€»è¾‘ã€‘
        # 1. å…ˆæ£€æŸ¥å…¨åº“æ˜¯å¦å·²æœ‰è¯¥äººç‰©
        if hasattr(group, 'characters'):
            from .models import Character
            if Character.objects.filter(name__iexact=tag_name).exists():
                char = Character.objects.get(name__iexact=tag_name)
                # çº æ­£å¤§å°å†™ä½“éªŒ
                if char.name != tag_name:
                    char.name = tag_name
                    char.save()
                group.characters.add(char)
                return JsonResponse({'status': 'success', 'tag_id': char.id, 'tag_name': char.name, 'tag_type': 'character'})
        
        # 2. å¦‚æœä¸æ˜¯äººç‰©ï¼Œåˆ™ä½œä¸ºæ™®é€šæ ‡ç­¾å¤„ç†
        tag, created = Tag.objects.get_or_create(name=tag_name)
        group.tags.add(tag)
        return JsonResponse({'status': 'success', 'tag_id': tag.id, 'tag_name': tag.name, 'tag_type': 'tag'})
        
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)})


@require_POST
def remove_tag_from_group(request, pk):
    group = get_object_or_404(PromptGroup, pk=pk)
    try:
        data = json.loads(request.body)
        tag_id = data.get('tag_id')
        tag_type = data.get('tag_type', 'tag') # æ¥æ”¶å‰ç«¯ä¼ æ¥çš„ç±»å‹ï¼Œé»˜è®¤ä¸º tag
        
        # ã€æ™ºèƒ½åˆ†æµåˆ é™¤é€»è¾‘ã€‘
        if tag_type == 'character' and hasattr(group, 'characters'):
            from .models import Character
            char = get_object_or_404(Character, pk=tag_id)
            group.characters.remove(char)
        else:
            tag = get_object_or_404(Tag, pk=tag_id)
            group.tags.remove(tag)
            
        return JsonResponse({'status': 'success'})
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)})
    
@require_GET
def group_list_api(request):
    """ã€å‡çº§ç‰ˆã€‘æä¾›å»é‡åçš„åˆ—è¡¨ï¼Œå¹¶é™„å¸¦ç»„å†…æ•°é‡"""
    query = request.GET.get('q', '')
    page_num = request.GET.get('page', 1)
    
    qs = PromptGroup.objects.all()
    
    if query:
        matching_group_ids = qs.filter(
            Q(title__icontains=query) |
            Q(prompt_text__icontains=query) |
            Q(prompt_text_zh__icontains=query) |
            Q(model_info__icontains=query) |       # åŠ ä¸Šæ¨¡å‹æœç´¢
            Q(characters__name__icontains=query) | # åŠ ä¸Šäººç‰©æœç´¢
            Q(tags__name__icontains=query)
        ).values_list('group_id', flat=True).distinct()
        
        qs = qs.filter(group_id__in=matching_group_ids)
    
    group_stats = qs.values('group_id').annotate(
        main_id=Max(Case(When(is_main_variant=True, then='id'), output_field=IntegerField())),
        max_id=Max('id'),     
        count=Count('id')     
    )
    
    # ä¼˜å…ˆå– main_id
    target_ids = [ (item['main_id'] or item['max_id']) for item in group_stats ]
    # å»ºç«‹ ID -> Count æ˜ å°„
    count_map = { (item['main_id'] or item['max_id']): item['count'] for item in group_stats }
    final_qs = PromptGroup.objects.filter(id__in=target_ids).order_by('-id')
    
    paginator = Paginator(final_qs, 20)
    page = paginator.get_page(page_num)
    
    data = []
    for group in page:
        cover_url = ""
        ## ã€ä¿®æ”¹é€»è¾‘ã€‘ä¼˜å…ˆå–æŒ‡å®šçš„ cover_imageï¼Œæ²¡æœ‰åˆ™æŒ‰åŸé€»è¾‘æ‰¾ç¬¬ä¸€å¼ å›¾
        cover_img = group.cover_image
        
        if not cover_img:
            images = group.images.all()
            # ä¼˜å…ˆæ‰¾éè§†é¢‘å›¾ç‰‡
            for img in images:
                if not img.is_video:
                    cover_img = img
                    break
            # å…œåº•
            if not cover_img and images.exists():
                cover_img = images.first()

        if cover_img:
            try:
                # å†æ¬¡æ£€æµ‹ï¼Œé˜²æ­¢è§†é¢‘è°ƒç”¨ thumbnail æŠ¥é”™
                if not cover_img.is_video and cover_img.thumbnail:
                    cover_url = cover_img.thumbnail.url
                else:
                    cover_url = cover_img.image.url
            except:
                pass
        
        data.append({
            'id': group.id,
            'title': group.title,
            'prompt_text': (group.prompt_text[:100] + '...') if group.prompt_text and len(group.prompt_text) > 100 else (group.prompt_text or ''),
            'created_at': group.created_at.strftime('%Y-%m-%d'),
            'cover_url': cover_url,
            'model_info': group.model_info or '',
            'group_id': str(group.group_id),
            'count': count_map.get(group.id, 1) 
        })
        
    return JsonResponse({
        'results': data,
        'has_next': page.has_next(),
        'next_page_number': page.next_page_number() if page.has_next() else None
    })

@require_POST
def merge_groups(request):
    try:
        data = json.loads(request.body)
        representative_ids = data.get('group_ids', [])
        
        if len(representative_ids) < 2:
            return JsonResponse({'status': 'error', 'message': 'è¯·è‡³å°‘é€‰æ‹©ä¸¤ä¸ªç»„è¿›è¡Œåˆå¹¶'})
            
        target_reps = PromptGroup.objects.filter(id__in=representative_ids)
        if not target_reps.exists():
            return JsonResponse({'status': 'error', 'message': 'æ‰¾ä¸åˆ°é€‰ä¸­çš„ç»„'})
            
        involved_group_ids = target_reps.values_list('group_id', flat=True).distinct()
        
        target_group_id = involved_group_ids[0]
        
        count = PromptGroup.objects.filter(group_id__in=involved_group_ids).update(group_id=target_group_id)
        
        return JsonResponse({
            'status': 'success', 
            'message': f'åˆå¹¶æˆåŠŸï¼å…± {count} ä¸ªç‰ˆæœ¬å·²å½’ä¸ºåŒä¸€ç³»åˆ—ã€‚'
        })
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)})
    
@require_POST
def unlink_group_relation(request, pk):
    group = get_object_or_404(PromptGroup, pk=pk)
    group.group_id = uuid.uuid4()
    group.save()
    return JsonResponse({'status': 'success'})

@require_POST
def link_group_relation(request, pk):
    current_group = get_object_or_404(PromptGroup, pk=pk)
    try:
        data = json.loads(request.body)
        
        target_ids = data.get('target_ids', [])
        if 'target_id' in data:
            target_ids.append(data['target_id'])
            
        if not target_ids:
             return JsonResponse({'status': 'error', 'message': 'æœªé€‰æ‹©ä»»ä½•ç‰ˆæœ¬'})

        # ã€æ ¸å¿ƒä¿®å¤ã€‘ä¸ä»…è·å–é€‰ä¸­çš„ IDï¼Œè¿˜è·å–å®ƒä»¬ä»£è¡¨çš„æ•´ä¸ªå®¶æ— group_id
        target_reps = PromptGroup.objects.filter(id__in=target_ids).exclude(id=current_group.id)
        target_group_ids = target_reps.values_list('group_id', flat=True).distinct()
        
        # å°†æ‰€æœ‰å±äºè¿™äº› group_id çš„è®°å½•ç»Ÿä¸€è¿ç§»
        groups_to_update = PromptGroup.objects.filter(group_id__in=target_group_ids).exclude(id=current_group.id)
        
        count = groups_to_update.update(group_id=current_group.group_id)
        
        return JsonResponse({'status': 'success', 'count': count})
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)})
    
@require_POST
def batch_delete_images(request):
    """æ‰¹é‡åˆ é™¤å›¾ç‰‡æ¥å£"""
    try:
        data = json.loads(request.body)
        image_ids = data.get('image_ids', [])
        
        if not image_ids:
            return JsonResponse({'status': 'error', 'message': 'æœªé€‰æ‹©ä»»ä½•å›¾ç‰‡'})

        # æŸ¥æ‰¾è¦åˆ é™¤çš„å¯¹è±¡
        images = ImageItem.objects.filter(id__in=image_ids)
        deleted_count = 0
        
        for img in images:
            # æ‰‹åŠ¨åˆ é™¤æ–‡ä»¶ï¼Œç¡®ä¿ä¸ç•™åƒåœ¾æ–‡ä»¶ï¼ˆå‚è€ƒåŸ delete_image é€»è¾‘ï¼‰
            if img.image:
                img.image.delete(save=False)
            img.delete()
            deleted_count += 1
            
        return JsonResponse({'status': 'success', 'count': deleted_count})
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)}, status=500)
    
# ã€æ–°å¢ã€‘è®¾ç½®å°é¢è§†å›¾
@require_POST
def set_group_cover(request, group_id, image_id):
    group = get_object_or_404(PromptGroup, pk=group_id)
    image = get_object_or_404(ImageItem, pk=image_id)
    
    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿å›¾ç‰‡å±äºè¯¥ç»„
    if image.group_id != group.id:
        return JsonResponse({'status': 'error', 'message': 'å›¾ç‰‡ä¸å±äºè¯¥ç»„'})
    
    group.cover_image = image
    group.save()
    return JsonResponse({'status': 'success'})

@require_GET
def get_similar_candidates(request, pk):
    """è·å–ç›¸ä¼¼æç¤ºè¯çš„æ¨èå€™é€‰ (ç”¨äºå…³è”ç‰ˆæœ¬)"""
    try:
        current_group = PromptGroup.objects.get(pk=pk)
    except PromptGroup.DoesNotExist:
        return JsonResponse({'status': 'error', 'message': 'Group not found'})

    my_content = (current_group.prompt_text or "").strip().lower()
    if len(my_content) < 5:
         return JsonResponse({'status': 'success', 'results': []})

    # 1. è·å–æ‰€æœ‰ç»„çš„æœ€æ–°ç‰ˆæœ¬ ID (é¿å…æ¨èåŒç»„çš„å†å²ç‰ˆæœ¬)
    group_stats = PromptGroup.objects.values('group_id').annotate(max_id=Max('id'))
    latest_ids = [item['max_id'] for item in group_stats]
    
    # 2. æŸ¥è¯¢å€™é€‰é›† (æ’é™¤å½“å‰ç»„ï¼Œé™åˆ¶æ•°é‡ä»¥ä¿è¯æ€§èƒ½)
    # å–æœ€æ–°çš„ 1000 ä¸ªç»„ä½œä¸ºå€™é€‰æ± 
    candidates = PromptGroup.objects.filter(id__in=latest_ids).exclude(group_id=current_group.group_id).order_by('-id')[:1000]
    
    recommendations = []
    
    for other in candidates:
        other_content = (other.prompt_text or "").strip().lower()
        if not other_content: continue
        
        # ç®€å•é¢„ç­›: é•¿åº¦å·®å¼‚è¿‡å¤§ç›´æ¥è·³è¿‡
        max_len = max(len(my_content), len(other_content))
        if max_len == 0: continue
        if abs(len(my_content) - len(other_content)) > max_len * 0.7: 
            continue

        # è®¡ç®—ç›¸ä¼¼åº¦
        ratio = difflib.SequenceMatcher(None, my_content, other_content).ratio()
        
        # ç›¸ä¼¼åº¦ > 30% å³å¯æ¨è (å…³è”æ¨èå¯ä»¥æ”¾å®½ä¸€ç‚¹)
        if ratio > 0.3: 
            recommendations.append((ratio, other))
            
    # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—ï¼Œå–å‰ 20 ä¸ª
    recommendations.sort(key=lambda x: x[0], reverse=True)
    top_recs = recommendations[:20]
    
    results = []
    for ratio, group in top_recs:
        # å¤ç”¨å°é¢è·å–é€»è¾‘
        cover_url = ""
        cover_img = group.cover_image # ä¼˜å…ˆç”¨å°é¢
        if not cover_img:
            images = group.images.all()
            for img in images:
                if not img.is_video:
                    cover_img = img
                    break
            if not cover_img and images.exists():
                cover_img = images.first()
        
        if cover_img:
             try:
                if not cover_img.is_video and cover_img.thumbnail:
                    cover_url = cover_img.thumbnail.url
                else:
                    cover_url = cover_img.image.url
             except:
                 pass
                 
        results.append({
            'id': group.id,
            'title': group.title,
            'prompt_text': group.prompt_text[:200] if group.prompt_text else '',
            'cover_url': cover_url,
            'similarity': f"{int(ratio*100)}%" # è¿”å›ç›¸ä¼¼åº¦ç™¾åˆ†æ¯”
        })
        
    return JsonResponse({'status': 'success', 'results': results})

@require_POST
def set_main_variant(request, pk):
    """å°†æŒ‡å®š PromptGroup è®¾ä¸ºè¯¥ç³»åˆ—çš„â€˜ä¸»ç‰ˆæœ¬â€™ (é¦–é¡µå±•ç¤º)"""
    target = get_object_or_404(PromptGroup, pk=pk)
    
    # 1. å°†åŒç»„çš„å…¶ä»–ç‰ˆæœ¬æ ‡è®°å–æ¶ˆ
    PromptGroup.objects.filter(group_id=target.group_id).update(is_main_variant=False)
    
    # 2. å°†å½“å‰ç‰ˆæœ¬è®¾ä¸ºä¸»ç‰ˆæœ¬
    target.is_main_variant = True
    target.save()
    
    return JsonResponse({'status': 'success'})

@require_POST
def add_ai_model(request):
    try:
        data = json.loads(request.body)
        name = data.get('name', '').strip()
        if not name:
             return JsonResponse({'status': 'error', 'message': 'æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º'})
        
        # åˆ›å»º AIModel (æ˜¾ç¤ºåœ¨ä¾§è¾¹æ /é¡¶éƒ¨)
        AIModel.objects.get_or_create(name=name)
        # åŒæ—¶åˆ›å»º Tag (ç”¨äºæœç´¢å…³è”)
        Tag.objects.get_or_create(name=name)
        
        return JsonResponse({'status': 'success'})
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)})
    
@require_GET
def create_view(request):
    """æ¸²æŸ“ AI ç‹¬ç«‹åˆ›ä½œå·¥ä½œå®¤é¡µé¢ï¼Œå¹¶å°†é…ç½®å’Œåˆå§‹æ•°æ®æ³¨å…¥å‰ç«¯"""
    template_id = request.GET.get('template_id')
    prompt_type = request.GET.get('prompt_type', 'positive')
    
    initial_data = {'prompt': '', 'tags': [], 'characters': [], 'reference_urls': []}
    
    if template_id:
        try:
            source_group = PromptGroup.objects.get(pk=template_id)
            
            selected_prompt = ""
            if prompt_type == 'positive' and source_group.prompt_text:
                selected_prompt = source_group.prompt_text
            elif prompt_type == 'positive_zh' and source_group.prompt_text_zh:
                selected_prompt = source_group.prompt_text_zh
            elif prompt_type == 'negative' and source_group.negative_prompt:
                selected_prompt = source_group.negative_prompt
            else:
                selected_prompt = source_group.prompt_text or source_group.prompt_text_zh or ""
                
            tags = [tag.name for tag in source_group.tags.all()]

            chars = []
            if hasattr(source_group, 'characters'):
                chars = [char.name for char in source_group.characters.all()]
            
            ref_urls = [ref.image.url for ref in source_group.references.all() if ref.image]
            if not ref_urls:
                first_img = source_group.images.first()
                if first_img and first_img.image:
                    ref_urls.append(first_img.image.url)
                    
            initial_data = {
                'prompt': selected_prompt, 
                'tags': tags, 
                'characters': chars,
                'reference_urls': ref_urls,
                'model_info': source_group.model_info  
            }
        except PromptGroup.DoesNotExist:
            pass

    # ã€æ–°å¢ã€‘è·å–å…¨åº“æ‰€æœ‰å·²æœ‰çš„æ ‡ç­¾åç§°åˆ—è¡¨
    all_tags = list(Tag.objects.values_list('name', flat=True).distinct())
    all_chars = []
    try:
        from .models import Character
        all_chars = list(Character.objects.values_list('name', flat=True).distinct())
    except Exception:
        pass

    return render(request, 'gallery/create.html', {
        'ai_config_json': json.dumps(AI_STUDIO_CONFIG),
        'initial_data_json': json.dumps(initial_data),
        'all_tags_json': json.dumps(all_tags),
        'all_chars_json': json.dumps(all_chars),
    })

@csrf_exempt
@require_POST
def api_generate_and_download(request):
    try:
        prompt = request.POST.get('prompt', '').strip()
        model_choice = request.POST.get('model_choice')
        base_image_files = request.FILES.getlist('base_images') 

        if not prompt:
            return JsonResponse({'status': 'error', 'message': 'æç¤ºè¯ä¸èƒ½ä¸ºç©º'})
            
        model_config = AI_STUDIO_CONFIG['models'].get(model_choice)
        if not model_config:
            return JsonResponse({'status': 'error', 'message': f'æœªçŸ¥çš„æ¨¡å‹: {model_choice}'})

        category_id = model_config['category']
        
        # 1. è·å–é»˜è®¤å‚æ•°
        api_args = {}
        for param in model_config.get('params', []):
            api_args[param['id']] = param['default']
        api_args['prompt'] = prompt

        # 2. åŠ¨æ€å‚æ•°æ™ºèƒ½è¦†å†™ä¸ç±»å‹è½¬æ¢
        for param in model_config.get('params', []):
            key = param['id']
            if key in request.POST:
                val = request.POST.get(key)
                default_val = param['default']
                try:
                    if isinstance(default_val, bool):
                        api_args[key] = str(val).lower() in ['true', '1', 'yes', 'on']
                    elif isinstance(default_val, int):
                        api_args[key] = int(val)
                    elif isinstance(default_val, float):
                        api_args[key] = float(val)
                    else:
                        api_args[key] = val
                except ValueError:
                    pass 

        # 3. è·å–ä¸Šä¼ å›¾ç‰‡åˆ—è¡¨ (æ§åˆ¶æœ€å¤§å¼ æ•°)
        files_to_upload = []
        img_max = next((cat['img_max'] for cat in AI_STUDIO_CONFIG['categories'] if cat['id'] == category_id), 0)
        if img_max > 0:
            if not base_image_files:
                return JsonResponse({'status': 'error', 'message': 'è¯¥æ¨¡å‹éœ€è¦è‡³å°‘ä¸€å¼ å‚è€ƒå›¾ç‰‡'})
            files_to_upload = base_image_files[:img_max]

        # ==========================================
        # æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šä½¿ç”¨é€‚é…å™¨æ¨¡å¼è¯·æ±‚äº‘ç«¯ï¼Œè§£è€¦ç¬¬ä¸‰æ–¹ SDK
        # ==========================================
        provider_name = model_config.get('provider', 'fal_ai')
        provider = get_ai_provider(provider_name)
        
        print(f"è°ƒç”¨é€šé“: {provider_name} | æ¨¡å‹: {model_choice} | å‚æ•°: {api_args}")
        
        try:
            # è·å–ç»Ÿä¸€æ ¼å¼çš„å›¾ç‰‡ URL åˆ—è¡¨
            generated_urls = provider.generate(model_config, api_args, files_to_upload)
        except Exception as e:
            error_str = str(e)
            # é’ˆå¯¹ç«å±±å¼•æ“æ•æ„Ÿå†…å®¹æ‹¦æˆªçš„ä¸“é¡¹å‹å¥½æç¤º
            if 'OutputImageSensitiveContentDetected' in error_str:
                friendly_msg = 'ç”Ÿæˆå¤±è´¥ï¼šè§¦å‘äº†å®˜æ–¹å®‰å…¨å®¡æ ¸æœºåˆ¶ã€‚ç”Ÿæˆçš„ç”»é¢æˆ–å‚è€ƒå«å›¾å¯èƒ½å­˜åœ¨æ•æ„Ÿç‰¹å¾ï¼Œè¯·å°è¯•ä¿®æ”¹æœè£…ã€å§¿æ€ç­‰æè¿°è¯ï¼Œæˆ–æ›´æ¢å«å›¾ï¼'
                return JsonResponse({'status': 'error', 'message': friendly_msg})
            elif 'InputSensitiveContentDetected' in error_str:
                friendly_msg = 'ç”Ÿæˆå¤±è´¥ï¼šè¾“å…¥çš„æç¤ºè¯è§¦å‘äº†å®‰å…¨è¿è§„è¯åº“ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®æ”¹æç¤ºè¯ã€‚'
                return JsonResponse({'status': 'error', 'message': friendly_msg})
            else:
                return JsonResponse({'status': 'error', 'message': f'äº‘ç«¯æ¥å£è°ƒç”¨å¤±è´¥: {error_str}'})

        if not generated_urls:
            return JsonResponse({'status': 'error', 'message': 'äº‘ç«¯æœªè¿”å›ä»»ä½•å›¾ç‰‡'})

        # ==========================================
        # 5. ä¸‹è½½æ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡ (ä¸šåŠ¡é€»è¾‘ä¿æŒä¸å˜)
        # ==========================================
        downloads_dir = r"G:\CommonData\å›¾ç‰‡\Imagegeneration_API" # æ ¹æ®ä½ çš„é…ç½®
        os.makedirs(downloads_dir, exist_ok=True) 
        
        base_timestamp = int(time.time())
        saved_paths = []
        final_urls = []

        print(f"äº‘ç«¯å…±ç”Ÿæˆäº† {len(generated_urls)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹å¤„ç†...")

        for idx, img_url in enumerate(generated_urls):
            # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šå¢åŠ åˆ¤ç©ºä¿æŠ¤ï¼Œè·³è¿‡ç”Ÿæˆå¤±è´¥çš„ç©º URL
            if not img_url:
                print(f"âš ï¸ ç¬¬ {idx+1} å¼ å›¾ç‰‡äº‘ç«¯æœªè¿”å› URLï¼Œå·²è·³è¿‡ã€‚")
                continue
                
            final_urls.append(img_url)
            file_name = f"Gen_{model_choice}_{base_timestamp}_{idx+1}.jpg" 
            file_path = os.path.join(downloads_dir, file_name)
            
            try:
                if img_url.startswith('data:image'):
                    # ã€æ–°å¢ã€‘å¦‚æœæ˜¯ Google ä¼ å›æ¥çš„ Base64 æ•°æ®ï¼Œç›´æ¥è§£ç å­˜å…¥ç¡¬ç›˜ï¼Œæ— éœ€å‘èµ·ç½‘ç»œè¯·æ±‚
                    header, encoded = img_url.split(",", 1)
                    with open(file_path, 'wb') as f:
                        f.write(base64.b64decode(encoded))
                    saved_paths.append(file_path)
                else:
                    # ã€ä¿ç•™ã€‘å¦‚æœæ˜¯ Fal/ç«å±± ä¼ å›æ¥çš„æ™®é€šå…¬ç½‘ URLï¼Œæ­£å¸¸ä½¿ç”¨ requests ä¸‹è½½
                    img_resp = requests.get(img_url, verify=False, timeout=60)
                    if img_resp.status_code == 200:
                        with open(file_path, 'wb') as f:
                            f.write(img_resp.content)
                        saved_paths.append(file_path)
            except Exception as e:
                print(f"å¤„ç†ç¬¬ {idx+1} å¼ å›¾ç‰‡å¤±è´¥: {e}")

        return JsonResponse({
            'status': 'success',
            'message': f'æˆåŠŸç”Ÿæˆå¹¶ä¸‹è½½äº† {len(saved_paths)} å¼ å›¾ç‰‡ï¼',
            'image_urls': final_urls,
            'saved_paths': saved_paths
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return JsonResponse({'status': 'error', 'message': str(e)}, status=500)
    
@csrf_exempt
@require_POST
def api_publish_studio_creation(request):
    """å¤„ç†ä» AI åˆ›ä½œå®¤ä¸€é”®å‘å¸ƒä½œå“å¡ç‰‡çš„è¯·æ±‚"""
    try:
        prompt = request.POST.get('prompt', '').strip()
        model_info = request.POST.get('model_info', '').strip()
        title = request.POST.get('title', '').strip()
        
        # ã€å…³é”®ä¿®æ­£ã€‘ï¼šç¡®ä¿åœ¨è¿™é‡Œä¸€èµ·è·å– tags_str å’Œ chars_str
        tags_str = request.POST.get('tags', '').strip()
        chars_str = request.POST.get('characters', '').strip() 
        
        saved_paths = request.POST.getlist('saved_paths') 
        
        if not saved_paths:
            return JsonResponse({'status': 'error', 'message': 'æ²¡æœ‰æ‰¾åˆ°ç”Ÿæˆçš„å›¾ç‰‡è·¯å¾„'})

        # 1. åˆ›å»º PromptGroup (æ™ºèƒ½æ¦‚æ‹¬ Prompt ç”Ÿæˆå¡ç‰‡æ ‡é¢˜)
        if not title:
            title = generate_smart_title(prompt)
            print(f"DEBUG: åˆ›ä½œå®¤ç”Ÿæˆäº†æ™ºèƒ½æ ‡é¢˜ -> {title}")
            
        group = PromptGroup.objects.create(
            title=title,
            prompt_text=prompt,
            model_info=model_info
        )
        
        # 2. ä¿å­˜æ™®é€šæ ‡ç­¾ (å•çº¯ä¿å­˜ï¼Œä¸å†æœ‰æ™ºèƒ½åˆ†æµ)
        if tags_str:
            for tag_name in tags_str.replace('ï¼Œ', ',').split(','):
                t_name = tag_name.strip()
                if t_name:
                    tag_obj, _ = Tag.objects.get_or_create(name=t_name)
                    group.tags.add(tag_obj)

        # 3. ç‹¬ç«‹ä¿å­˜äººç‰©æ ‡ç­¾
        if chars_str:
            try:
                from .models import Character
                for char_name in chars_str.replace('ï¼Œ', ',').split(','):
                    c_name = char_name.strip()
                    if c_name:
                        char_obj, _ = Character.objects.get_or_create(name=c_name)
                        group.characters.add(char_obj)
            except Exception as e:
                print(f"äººç‰©ä¿å­˜å¼‚å¸¸: {e}")
        
        # 4. å°†æœ¬åœ°æˆå›¾æ–‡ä»¶è¯»å–å¹¶å­˜å…¥ Django çš„ ImageItem (ç»‘å®šåˆ°ç»„)
        created_image_ids = []
        for path in saved_paths:
            if os.path.exists(path):
                with open(path, 'rb') as f:
                    file_content = ContentFile(f.read())
                    file_name = os.path.basename(path)
                    img_item = ImageItem(group=group)
                    img_item.image.save(file_name, file_content, save=True)
                    created_image_ids.append(img_item.id)
        
        # 5. å¦‚æœç”¨æˆ·ä¸Šä¼ äº†å‚è€ƒå›¾ï¼Œä¸€å¹¶å­˜ä¸ºå‚è€ƒå›¾
        ref_files = request.FILES.getlist('references')
        for rf in ref_files:
            ReferenceItem.objects.create(group=group, image=rf)
        
        # 6. è§¦å‘åå°å¤„ç†ç”Ÿæˆç¼©ç•¥å›¾ç­‰
        if created_image_ids:
            # å¼•å…¥ trigger_background_processing (å¦‚æœä½ åœ¨æ–‡ä»¶é¡¶éƒ¨æ²¡å¼•å…¥ï¼Œè¿™é‡Œåšä¸ªä¿é™©)
            from .services import trigger_background_processing
            trigger_background_processing(created_image_ids)
            
        return JsonResponse({'status': 'success', 'group_id': group.id, 'message': 'å‘å¸ƒæˆåŠŸï¼'})
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return JsonResponse({'status': 'error', 'message': str(e)}, status=500)

@csrf_exempt
@require_POST
def api_get_similar_groups_by_prompt(request):
    """æ ¹æ®å‰ç«¯ä¼ æ¥çš„ Prompt æ–‡æœ¬ï¼Œè®¡ç®—å…¨åº“ç›¸ä¼¼åº¦å¹¶è¿”å›æ’åºåçš„ä½œå“åˆ—è¡¨ (åŒ…å«æ‰€æœ‰ç³»åˆ—çš„å†å²ç‰ˆæœ¬)"""
    try:
        data = json.loads(request.body)
        prompt_text = data.get('prompt', '').strip().lower()
        
        candidates = PromptGroup.objects.all().order_by('-id')[:2000]
        recommendations = []
        
        for other in candidates:
            other_content = (other.prompt_text or "").strip().lower()
            if len(prompt_text) > 0 and len(other_content) > 0:
                ratio = difflib.SequenceMatcher(None, prompt_text, other_content).ratio()
            elif len(prompt_text) == 0:
                ratio = 0.0 
            else:
                continue
            recommendations.append((ratio, other.id, other))
            
        recommendations.sort(key=lambda x: (x[0], x[1]), reverse=True)
        top_recs = recommendations[:15]
        
        results = []
        for ratio, group_id, group in top_recs:
            cover_url = ""
            cover_img = group.cover_image
            if not cover_img:
                images = group.images.all()
                for img in images:
                    if not img.is_video:
                        cover_img = img
                        break
                if not cover_img and images.exists():
                    cover_img = images.first()
            
            if cover_img:
                 try:
                    if not cover_img.is_video and cover_img.thumbnail:
                        cover_url = cover_img.thumbnail.url
                    else:
                        cover_url = cover_img.image.url
                 except:
                     pass
            
            # ã€é‡ç‚¹æ–°å¢ã€‘ï¼šæå–äººç‰©æ ‡ç­¾åˆ—è¡¨
            chars_list = []
            if hasattr(group, 'characters'):
                chars_list = [char.name for char in group.characters.all()]
                     
            results.append({
                'id': group.id,
                'title': group.title,
                'prompt_text': group.prompt_text[:100] + '...' if group.prompt_text and len(group.prompt_text)>100 else (group.prompt_text or 'æ— æç¤ºè¯'),
                'cover_url': cover_url,
                'similarity': f"{int(ratio*100)}%" if len(prompt_text) > 0 else "-",
                'model_info': group.model_info or "æ— æ¨¡å‹",
                'characters': chars_list # ã€é‡ç‚¹æ–°å¢ã€‘ï¼šä¼ ç»™å‰ç«¯
            })
            
        return JsonResponse({'status': 'success', 'results': results})
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)})

@csrf_exempt
@require_POST
def api_append_to_existing_group(request):
    """å°†ç”Ÿæˆçš„æœ¬åœ°å›¾ç‰‡è¿½åŠ åˆ°ç°æœ‰çš„ PromptGroup ä¸­"""
    try:
        group_id = request.POST.get('group_id')
        saved_paths = request.POST.getlist('saved_paths')
        
        if not group_id or not saved_paths:
            return JsonResponse({'status': 'error', 'message': 'å‚æ•°ç¼ºå¤±'})
            
        group = PromptGroup.objects.get(pk=group_id)
        created_image_ids = []
        
        for path in saved_paths:
            if os.path.exists(path):
                with open(path, 'rb') as f:
                    file_content = ContentFile(f.read())
                    file_name = os.path.basename(path)
                    img_item = ImageItem(group=group)
                    img_item.image.save(file_name, file_content, save=True)
                    created_image_ids.append(img_item.id)
                    
        # è§¦å‘åå°å¤„ç†ï¼ˆç”Ÿæˆç‰¹å¾å‘é‡ã€ç¼©ç•¥å›¾ç­‰ï¼‰
        if created_image_ids:
            from .services import trigger_background_processing
            trigger_background_processing(created_image_ids)
            
        return JsonResponse({'status': 'success', 'group_id': group.id, 'message': 'æˆåŠŸè¿½åŠ åˆ°è¯¥ä½œå“ï¼'})
    except PromptGroup.DoesNotExist:
        return JsonResponse({'status': 'error', 'message': 'ç›®æ ‡ä½œå“ç»„ä¸å­˜åœ¨'})
    except Exception as e:
        import traceback
        traceback.print_exc()
        return JsonResponse({'status': 'error', 'message': str(e)})
    
@require_POST
def edit_model_api(request):
    """å¤„ç†å‰ç«¯ä¿®æ”¹æ¨¡å‹æ ‡ç­¾åç§°çš„è¯·æ±‚ï¼ˆç»ˆæå®¹é”™ä¸è„æ•°æ®æ¸…ç†ç‰ˆï¼‰"""
    try:
        data = json.loads(request.body)
        old_name = data.get('old_name', '').strip()
        new_name = data.get('new_name', '').strip()

        if not old_name or not new_name:
            return JsonResponse({'status': 'error', 'message': 'æ ‡ç­¾åç§°ä¸èƒ½ä¸ºç©º'})

        if old_name == new_name:
            return JsonResponse({'status': 'success', 'message': 'åç§°æœªæ”¹å˜'})

        with transaction.atomic(): 
            # ==========================================
            # 1. å®‰å…¨è·å–æˆ–åˆ›å»ºæ–°æ ‡ç­¾ (å…ç–« MultipleObjectsReturned)
            # ==========================================
            new_tags = list(Tag.objects.filter(name__iexact=new_name))
            if new_tags:
                new_tag = new_tags[0] # å¦‚æœæœ‰å¤šä¸ªåŒåæ–°æ ‡ç­¾ï¼Œé€‰ç¬¬ä¸€ä¸ªå½“â€œè€å¤§â€
                # å¦‚æœè€å¤§åå­—å¤§å°å†™è·Ÿç”¨æˆ·è¾“å…¥çš„ä¸å®Œå…¨ä¸€è‡´ï¼Œçº æ­£å®ƒ
                if new_tag.name != new_name:
                    new_tag.name = new_name
                    new_tag.save()
            else:
                new_tag = Tag.objects.create(name=new_name)

            # ==========================================
            # 2. æ‰¾åˆ°æ‰€æœ‰æ—§æ ‡ç­¾ï¼ˆåŒ…æ‹¬é‡å¤çš„è„æ•°æ®ï¼‰ï¼Œå…¨éƒ¨åˆå¹¶åˆ°è€å¤§èº«ä¸Š
            # ==========================================
            old_tags = list(Tag.objects.filter(name__iexact=old_name))
            
            for old_tag in old_tags:
                if old_tag.id != new_tag.id:
                    # è·å–ä½¿ç”¨äº†è¿™ä¸ªæ—§æ ‡ç­¾çš„æ‰€æœ‰ç”»ä½œç»„
                    groups_with_old_tag = old_tag.promptgroup_set.all()
                    for group in groups_with_old_tag:
                        group.tags.add(new_tag)    # ç»‘ä¸Šæ–°æ ‡ç­¾è€å¤§
                        group.tags.remove(old_tag) # è§£ç»‘æ—§æ ‡ç­¾
                    
                    # æ¦¨å¹²åˆ©ç”¨ä»·å€¼åï¼ŒæŠŠè¿™ä¸ªæ—§æ ‡ç­¾ï¼ˆæˆ–é‡å¤çš„è„æ ‡ç­¾ï¼‰æ— æƒ…åˆ é™¤
                    old_tag.delete()

            # ==========================================
            # 3. å¤„ç† AIModel è¡¨ï¼Œä¿è¯é¡¶éƒ¨çš„ Tab æ æ›´æ–°
            # ==========================================
            old_ai_models = AIModel.objects.filter(name__iexact=old_name)
            old_ai_models.delete() # åˆ æ‰æ‰€æœ‰æ—§çš„ Tab å
            
            # ç¡®ä¿æ–°åå­—è¢«æ³¨å†Œåˆ° AIModel è¡¨ä¸­ (ä½¿ç”¨ filter_first é€»è¾‘é˜²æŠ¥é”™)
            if not AIModel.objects.filter(name__iexact=new_name).exists():
                AIModel.objects.create(name=new_name)

            # ==========================================
            # 4. åŒæ­¥æ›´æ–°çº¯æ–‡æœ¬å­—æ®µ model_info
            # ==========================================
            groups_to_update = PromptGroup.objects.filter(model_info__iexact=old_name)
            updated_count = groups_to_update.update(model_info=new_name)

        return JsonResponse({
            'status': 'success', 
            'message': f'é‡å‘½åæˆåŠŸï¼å·²æ¸…ç†é‡å¤è„æ•°æ®ï¼Œå¹¶åŒæ­¥äº† {updated_count} å¼ å¡ç‰‡ã€‚'
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return JsonResponse({'status': 'error', 'message': str(e)})

@csrf_exempt
@require_POST
def api_generate_title(request):
    """å‰ç«¯å¼‚æ­¥è¯·æ±‚æ™ºèƒ½æ ‡é¢˜æ¥å£"""
    try:
        data = json.loads(request.body)
        prompt = data.get('prompt', '').strip()
        
        if not prompt:
            return JsonResponse({'status': 'success', 'title': 'AI ç‹¬ç«‹åˆ›ä½œ'})
            
        # è°ƒç”¨ç°æˆçš„æœ¬åœ° LLM æ ‡é¢˜æ¦‚æ‹¬å‡½æ•°
        title = generate_smart_title(prompt)
        return JsonResponse({'status': 'success', 'title': title})
        
    except Exception as e:
        return JsonResponse({'status': 'error', 'message': str(e)})